{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from load_data import gen_data,load_data,standardize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "num_steps = 70\n",
    "\n",
    "\n",
    "input_num = 5\n",
    "output_num = 1\n",
    "\n",
    "state_size = 100\n",
    "\n",
    "num_layers = 20\n",
    "\n",
    "def lrelu(x, name, leak=0.2): \n",
    "  #  return tf.maximum(x, leak * x, name=name) \n",
    "    return tf.maximum(x, 0, name=name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, [None, num_steps,input_num], name='input_placeholder')\n",
    "y = tf.placeholder(tf.float32, [None], name='labels_placeholder')\n",
    "\n",
    "keep_prob = tf.placeholder_with_default(1.0, shape=())\n",
    "\n",
    "\n",
    "\n",
    "x_reshaped = tf.reshape(x,[tf.shape(x)[0],x.shape[1],1,x.shape[2]])\n",
    "\n",
    "\n",
    "\n",
    "#conv1 = lrelu(tf.layers.conv2d(x_reshaped,name=\"conv1\", filters = 8, \n",
    "#                         kernel_size = [4,1],strides = [1,1],padding = \"valid\", activation = None),\"conv1_lrelu\")\n",
    "\n",
    "#conv2 = lrelu(tf.layers.conv2d(conv1, name=\"conv2\", filters = 16, \n",
    "#                         kernel_size = [4,1],strides = [1,1],padding = \"valid\", activation = None),\"conv2_lrelu\")\n",
    "\n",
    "#pool1 = tf.layers.max_pooling2d(inputs=conv2, name = \"pool1\", pool_size=[2, 1], strides=[2,1])\n",
    "\n",
    "#conv3 = lrelu(tf.layers.conv2d(pool1, name=\"conv3\", filters = 8, \n",
    "#                         kernel_size = [4,1],strides = [1,1],padding = \"valid\", activation = None),\"conv3_lrelu\")\n",
    "#bn3 = tf.contrib.layers.batch_norm(conv3,is_training=is_training, scope='bn3')\n",
    "\n",
    "#conv4 = lrelu(tf.layers.conv2d(conv3, name=\"conv4\", filters = 16, \n",
    "#                         kernel_size = [4,1],strides = [1,1],padding = \"valid\", activation = None),\"conv4_lrelu\")\n",
    "#bn4 = tf.contrib.layers.batch_norm(conv4,is_training=is_training, scope='bn4')\n",
    "\n",
    "\n",
    "#pool2 = tf.layers.max_pooling2d(inputs=bn4, name = \"pool2\", pool_size=[2, 1], strides=[1,1])\n",
    "rnn_inputs = tf.squeeze(x_reshaped,axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(?, 70, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(x_reshaped)\n",
    "#print(conv1)\n",
    "#print(conv2)\n",
    "#print(pool1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "cells = []\n",
    "for i in range(0, num_layers):\n",
    "    cell = tf.contrib.rnn.LSTMCell(state_size )\n",
    "    #cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "    cells.append(cell)\n",
    "    \n",
    "mul_cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "\n",
    "rnn_outputs, final_state = tf.nn.dynamic_rnn(mul_cell, rnn_inputs, dtype=tf.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_outputs_reshaped = tf.reshape(rnn_outputs,[tf.shape(rnn_outputs)[0],\n",
    "                                               rnn_outputs.shape[1],1,rnn_outputs.shape[2]])\n",
    "conv5 = lrelu(tf.layers.conv2d(rnn_outputs_reshaped, name=\"conv5\", filters = 128, \n",
    "                         kernel_size = [4,1],strides = [1,1],padding = \"valid\", activation = None),\"conv5_lrelu\")\n",
    "\n",
    "conv6 = lrelu(tf.layers.conv2d(conv5, name=\"conv6\", filters = 256, \n",
    "                         kernel_size = [4,1],strides = [1,1],padding = \"valid\", activation = None),\"conv6_lrelu\")\n",
    "\n",
    "pool3 = tf.layers.max_pooling2d(inputs=conv6, name = \"pool3\", pool_size=[2, 1], strides=[1,1])\n",
    "\n",
    "conv7 = lrelu(tf.layers.conv2d(pool3, name=\"conv7\", filters = 64, \n",
    "                         kernel_size = [4,1],strides = [1,1],padding = \"valid\", activation = None),\"conv7_lrelu\")\n",
    "\n",
    "conv8 = lrelu(tf.layers.conv2d(conv7, name=\"conv8\", filters = 128, \n",
    "                         kernel_size = [4,1],strides = [1,1],padding = \"valid\", activation = None),\"conv8_lrelu\")\n",
    "\n",
    "pool4 = tf.layers.max_pooling2d(inputs=conv8, name = \"pool4\", pool_size=[2, 1], strides=[1,1])\n",
    "\n",
    "conv9 = lrelu(tf.layers.conv2d(pool4, name=\"conv9\", filters = 32, \n",
    "                         kernel_size = [4,1],strides = [1,1],padding = \"valid\", activation = None),\"conv9_lrelu\")\n",
    "\n",
    "conv10 = lrelu(tf.layers.conv2d(conv9, name=\"conv10\", filters = 64, \n",
    "                         kernel_size = [4,1],strides = [1,1],padding = \"valid\", activation = None),\"conv10_lrelu\")\n",
    "\n",
    "\n",
    "pool5 = tf.layers.max_pooling2d(inputs=conv10, name = \"pool5\", pool_size=[4, 1], strides=[2,1])\n",
    "\n",
    "\n",
    "pool5_flat = tf.reshape(pool5,[tf.shape(pool5)[0],pool5.shape[1]*pool5.shape[2]*pool5.shape[3]])\n",
    "\n",
    "\n",
    "#rnn_outputs_flat = tf.reshape(rnn_outputs,[tf.shape(rnn_outputs)[0],rnn_outputs.shape[1]*rnn_outputs.shape[2]])\n",
    "dense1 = tf.layers.dense(pool5_flat,512,name=\"dense1\")\n",
    "dense2 = tf.layers.dense(dense1,output_num,name=\"dense2\")\n",
    "\n",
    "logits = tf.squeeze(dense2,axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rnn_outputs_flat =  tf.reshape(rnn_outputs,[tf.shape(rnn_outputs)[0],\n",
    "                                               rnn_outputs.shape[1]*rnn_outputs.shape[2]])\n",
    "#dropout = tf.nn.dropout(dense1, keep_prob=keep_prob)\n",
    "\n",
    "dense1 = tf.layers.dense(rnn_outputs_flat,1024,name=\"dense1\")\n",
    "dense2 = tf.layers.dense(dense1,256,name=\"dense2\")\n",
    "dense3 = tf.layers.dense(dense2,output_num,name=\"dense3\")\n",
    "\n",
    "logits = tf.squeeze(dense3,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn/transpose:0\", shape=(?, 70, 100), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(rnn_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_1:0\", shape=(?, 70, 1, 100), dtype=float32)\n",
      " \n",
      "Tensor(\"conv5_lrelu:0\", shape=(?, 67, 1, 128), dtype=float32)\n",
      "Tensor(\"conv6_lrelu:0\", shape=(?, 64, 1, 256), dtype=float32)\n",
      "Tensor(\"pool3/MaxPool:0\", shape=(?, 63, 1, 256), dtype=float32)\n",
      " \n",
      "Tensor(\"conv7_lrelu:0\", shape=(?, 60, 1, 64), dtype=float32)\n",
      "Tensor(\"conv8_lrelu:0\", shape=(?, 57, 1, 128), dtype=float32)\n",
      "Tensor(\"pool4/MaxPool:0\", shape=(?, 56, 1, 128), dtype=float32)\n",
      " \n",
      "Tensor(\"conv9_lrelu:0\", shape=(?, 53, 1, 32), dtype=float32)\n",
      "Tensor(\"conv10_lrelu:0\", shape=(?, 50, 1, 64), dtype=float32)\n",
      "Tensor(\"pool5/MaxPool:0\", shape=(?, 24, 1, 64), dtype=float32)\n",
      " \n",
      "Tensor(\"dense1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "Tensor(\"dense2/BiasAdd:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(rnn_outputs_reshaped)\n",
    "print(\" \")\n",
    "print(conv5)\n",
    "print(conv6)\n",
    "print(pool3)\n",
    "print(\" \")\n",
    "print(conv7)\n",
    "print(conv8)\n",
    "print(pool4)\n",
    "print(\" \")\n",
    "print(conv9)\n",
    "print(conv10)\n",
    "print(pool5)\n",
    "print(\" \")\n",
    "print(dense1)\n",
    "print(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y - logits))\n",
    "loss_sum = tf.summary.scalar('Loss', loss)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(learning_rate = 0.0002).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "resample=\"2H\"\n",
    "\n",
    "restore_checkpoint = False\n",
    "save = False\n",
    "tensorboard = True\n",
    "\n",
    "\n",
    "if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "else:\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'logs/train': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!rm -r logs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calgary Energy Balance 5min 2013\n",
      "Calgary Water Balance 5min 2013\n",
      "Calgary Lysimeters kg 5min2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/Recurrent/load_data.py:77: FutureWarning: how in .resample() is deprecated\n",
      "the new syntax is .resample(...)..apply(<func>)\n",
      "  'Wind': \"mean\",'Rain': \"sum\",'Lysimeter': \"mean\"})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London Energy Balance 5min 2013\n",
      "London Water Balance 5min 2013\n",
      "London Lysimeters kg 5min2013\n",
      "Calgary Energy Balance 5min 2014\n",
      "Calgary Water Balance 5min 2014\n",
      "Calgary Lysimeters kg 5min2014\n",
      "London Energy Balance 5min 2014\n",
      "London Water Balance 5min 2014\n",
      "London Lysimeters kg 5min2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py:2245: FutureWarning: In the future, 'NAT < x' and 'x < NAT' will always be False.\n",
      "  self._values[0] < other_diff[0]\n"
     ]
    }
   ],
   "source": [
    "data = load_data([\"Calgary\",\"London\"],['2013','2014'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 0  loss : 283.38092041015625  \n",
      "real : [ 14.26952149  16.79191192  18.10677497]   \n",
      "pred : [  5.27612904e-08   6.60950477e-08   4.61803893e-08]\n",
      "\n",
      "Iteration : 25  loss : 10.448774337768555  \n",
      "real : [ 13.95049164  14.44305052  15.06310846]   \n",
      "pred : [ 11.09905624  11.08977413  11.09439182]\n",
      "\n",
      "Iteration : 50  loss : 0.9785699844360352  \n",
      "real : [ 16.21181     14.87755593  15.64407931]   \n",
      "pred : [ 14.37176514  14.38300133  14.37356377]\n",
      "\n",
      "Iteration : 75  loss : 25.188926696777344  \n",
      "real : [ 14.08808752  16.77470599  13.83602841]   \n",
      "pred : [ 12.65581608  12.64486313  12.64778519]\n",
      "\n",
      "Iteration : 100  loss : 2.023662805557251  \n",
      "real : [ 15.71140811  11.00624889  12.32250856]   \n",
      "pred : [ 14.39054775  14.39042091  14.39038754]\n",
      "\n",
      "Iteration : 125  loss : 4.1287126541137695  \n",
      "real : [ 13.75033846  15.9957432   15.74559304]   \n",
      "pred : [ 16.80883789  16.8179512   16.81812668]\n",
      "\n",
      "Iteration : 150  loss : 16.108997344970703  \n",
      "real : [ 17.62688407  16.10280974  13.74236414]   \n",
      "pred : [ 13.80116653  13.80372524  13.7939415 ]\n",
      "\n",
      "Iteration : 175  loss : 2.7152438163757324  \n",
      "real : [ 14.9815023   13.11600141  15.90717608]   \n",
      "pred : [ 12.967103    12.97960377  12.96760654]\n",
      "\n",
      "Iteration : 200  loss : 32.70307922363281  \n",
      "real : [ 18.6741172   18.6741172   14.42003905]   \n",
      "pred : [ 12.17466927  12.17466927  12.141922  ]\n",
      "\n",
      "Iteration : 225  loss : 1.0778719186782837  \n",
      "real : [ 13.80768511  13.64856759  13.11297616]   \n",
      "pred : [ 14.72645473  14.70282936  14.71681309]\n",
      "\n",
      "Iteration : 250  loss : 7.530646324157715  \n",
      "real : [ 16.7510072   13.91662249  15.21202807]   \n",
      "pred : [ 13.45950603  13.53333759  13.51139832]\n",
      "\n",
      "Iteration : 275  loss : 6.489826679229736  \n",
      "real : [ 13.19860168  14.1152196   13.37339294]   \n",
      "pred : [ 15.72951126  15.77071667  15.46835232]\n",
      "\n",
      "Iteration : 300  loss : 5.364562511444092  \n",
      "real : [ 18.17494574  16.68646992  14.18395651]   \n",
      "pred : [ 15.66555119  14.62668705  14.4830389 ]\n",
      "\n",
      "Iteration : 325  loss : 8.921390533447266  \n",
      "real : [ 17.01065652  14.15303483  15.97074631]   \n",
      "pred : [ 13.894557    13.4482336   13.38318729]\n",
      "\n",
      "Iteration : 350  loss : 1.362146019935608  \n",
      "real : [ 17.0112462   17.04840385  16.54089774]   \n",
      "pred : [ 15.95412827  15.9171896   15.69943523]\n",
      "\n",
      "Iteration : 375  loss : 1.8462519645690918  \n",
      "real : [ 14.50229063  13.97719257  14.96448107]   \n",
      "pred : [ 12.76948166  12.73295593  12.84242821]\n",
      "\n",
      "Iteration : 400  loss : 1.1194803714752197  \n",
      "real : [ 14.096248    13.60133106  15.2403964 ]   \n",
      "pred : [ 14.7364769   15.06844902  14.73379517]\n",
      "\n",
      "Iteration : 425  loss : 2.69132399559021  \n",
      "real : [ 13.65467303  15.18520981  13.95049164]   \n",
      "pred : [ 16.60676956  16.76421928  16.59788704]\n",
      "\n",
      "Iteration : 450  loss : 2.8809173107147217  \n",
      "real : [ 17.10729867  14.61094364  21.1442114 ]   \n",
      "pred : [ 17.04150581  15.34234905  18.1104641 ]\n",
      "\n",
      "Iteration : 475  loss : 4.247350215911865  \n",
      "real : [ 15.6114053   15.25317948  14.00596162]   \n",
      "pred : [ 14.28452587  14.51026535  14.40691566]\n",
      "\n",
      "Iteration : 500  loss : 2.341122627258301  \n",
      "real : [ 16.50739427  13.53495307  13.82325681]   \n",
      "pred : [ 13.39432526  12.75264835  12.83227825]\n",
      "\n",
      "Iteration : 525  loss : 1.4908627271652222  \n",
      "real : [ 12.97057209  12.5142077   13.35477248]   \n",
      "pred : [ 13.55196476  13.40171814  13.47569466]\n",
      "\n",
      "Iteration : 550  loss : 2.301835060119629  \n",
      "real : [ 14.29167888  17.76943529  15.58394388]   \n",
      "pred : [ 14.59803581  17.82768631  14.60684967]\n",
      "\n",
      "Iteration : 575  loss : 0.9630361795425415  \n",
      "real : [ 14.47889725  15.11294383  13.39729214]   \n",
      "pred : [ 14.68089867  14.53870773  14.58592606]\n",
      "\n",
      "Iteration : 600  loss : 1.6590018272399902  \n",
      "real : [ 17.87674005  14.72286353  18.43099694]   \n",
      "pred : [ 19.04101753  15.8214159   18.85099602]\n",
      "\n",
      "Iteration : 625  loss : 4.303337097167969  \n",
      "real : [ 12.85552882  13.91267352  14.51280079]   \n",
      "pred : [ 14.9148283   15.08731461  15.17015266]\n",
      "\n",
      "Iteration : 650  loss : 1.408814787864685  \n",
      "real : [ 12.2006869   13.27296856  13.89040338]   \n",
      "pred : [ 13.10603523  13.15854549  13.20101166]\n",
      "\n",
      "Iteration : 675  loss : 10.03376579284668  \n",
      "real : [ 16.85018942  16.81425056  17.03029044]   \n",
      "pred : [ 12.90915489  12.91475582  12.80718613]\n",
      "\n",
      "Iteration : 700  loss : 1.2387199401855469  \n",
      "real : [ 16.91699081  15.31034649  13.80570705]   \n",
      "pred : [ 14.92559624  14.82198715  14.85966301]\n",
      "\n",
      "Iteration : 725  loss : 5.914966106414795  \n",
      "real : [ 13.18992625  14.17899206  15.13023321]   \n",
      "pred : [ 15.50261307  15.20461845  15.11131668]\n",
      "\n",
      "Iteration : 750  loss : 4.872683525085449  \n",
      "real : [ 15.1017887   13.80336664  13.77104217]   \n",
      "pred : [ 16.23058128  16.24875641  16.11484528]\n",
      "\n",
      "Iteration : 775  loss : 4.3737359046936035  \n",
      "real : [ 13.1802693   12.85311128  13.237069  ]   \n",
      "pred : [ 14.6926527   14.68371964  14.84613228]\n",
      "\n",
      "Iteration : 800  loss : 1.017940640449524  \n",
      "real : [ 11.67275636  12.87668763  12.55303122]   \n",
      "pred : [ 13.32888317  13.37852764  13.33237553]\n",
      "\n",
      "Iteration : 825  loss : 2.23415470123291  \n",
      "real : [ 14.09531551  16.971547    17.03987815]   \n",
      "pred : [ 14.33985519  14.344491    14.36229801]\n",
      "\n",
      "Iteration : 850  loss : 2.6468007564544678  \n",
      "real : [ 13.99099818  17.5275129   15.60532317]   \n",
      "pred : [ 15.23296452  19.1881752   18.23447609]\n",
      "\n",
      "Iteration : 875  loss : 4.851588249206543  \n",
      "real : [ 21.13450211  18.33049356  16.96696089]   \n",
      "pred : [ 16.65372086  17.73011589  13.7305584 ]\n",
      "\n",
      "Iteration : 900  loss : 3.3775634765625  \n",
      "real : [ 18.74732201  16.52299092  21.86829016]   \n",
      "pred : [ 19.38010406  13.93311501  19.36982155]\n",
      "\n",
      "Iteration : 925  loss : 1.0269224643707275  \n",
      "real : [ 13.57129352  14.14920627  13.1520338 ]   \n",
      "pred : [ 14.84848118  14.84460354  14.82943821]\n",
      "\n",
      "Iteration : 950  loss : 0.7865667343139648  \n",
      "real : [ 12.55317864  14.2046727   11.8382647 ]   \n",
      "pred : [ 13.06130505  13.14828205  13.07881165]\n",
      "\n",
      "Iteration : 975  loss : 1.0421009063720703  \n",
      "real : [ 16.72384971  17.22808955  17.1295009 ]   \n",
      "pred : [ 14.95646763  16.6265583   17.85959244]\n",
      "\n",
      "Iteration : 1000  loss : 2.9050590991973877  \n",
      "real : [ 13.30196579  13.09095279  16.67538287]   \n",
      "pred : [ 13.26073265  13.31563187  13.34664536]\n",
      "\n",
      "Iteration : 1025  loss : 0.886803925037384  \n",
      "real : [ 15.58662821  16.26774985  18.21001393]   \n",
      "pred : [ 15.08724976  15.17092037  17.27330971]\n",
      "\n",
      "Iteration : 1050  loss : 3.0344748497009277  \n",
      "real : [ 14.23299154  15.1912479   15.87874241]   \n",
      "pred : [ 13.97866154  14.00937271  13.93231106]\n",
      "\n",
      "Iteration : 1075  loss : 2.8397128582000732  \n",
      "real : [ 16.54321714  17.1132969   16.58043424]   \n",
      "pred : [ 14.34611607  14.3293581   14.28093529]\n",
      "\n",
      "Iteration : 1100  loss : 1.923269510269165  \n",
      "real : [ 18.56654333  18.36062391  16.05206766]   \n",
      "pred : [ 17.95696068  16.67059708  18.33738518]\n",
      "\n",
      "Iteration : 1125  loss : 6.578706741333008  \n",
      "real : [ 19.13966925  15.53987469  16.56790737]   \n",
      "pred : [ 17.25148201  13.37266159  12.8241415 ]\n",
      "\n",
      "Iteration : 1150  loss : 3.188187599182129  \n",
      "real : [ 16.44208264  19.39104927  13.90510018]   \n",
      "pred : [ 14.99208927  18.07603073  13.73332977]\n",
      "\n",
      "Iteration : 1175  loss : 5.300788402557373  \n",
      "real : [ 19.39468238  14.7653688   14.90841494]   \n",
      "pred : [ 17.47954559  13.78905582  13.37803459]\n",
      "\n",
      "Iteration : 1200  loss : 1.2806005477905273  \n",
      "real : [ 13.14677369  12.64321715  13.51633768]   \n",
      "pred : [ 12.90007877  12.9473896   12.99415207]\n",
      "\n",
      "Iteration : 1225  loss : 6.341562271118164  \n",
      "real : [ 14.28919475  13.58923302  12.79478445]   \n",
      "pred : [ 15.61423397  17.83333015  15.2991581 ]\n",
      "\n",
      "Iteration : 1250  loss : 5.937373638153076  \n",
      "real : [ 13.73332329  16.42188462  14.4785614 ]   \n",
      "pred : [ 16.46804619  16.47846794  16.28889084]\n",
      "\n",
      "Iteration : 1275  loss : 1.273235559463501  \n",
      "real : [ 13.21503558  14.44305052  13.82325681]   \n",
      "pred : [ 13.790308   14.0112114  14.141469 ]\n",
      "\n",
      "Iteration : 1300  loss : 2.823962926864624  \n",
      "real : [ 16.63753181  16.72549974  15.44044518]   \n",
      "pred : [ 15.31828499  16.57566833  14.15657616]\n",
      "\n",
      "Iteration : 1325  loss : 2.771501064300537  \n",
      "real : [ 19.92116651  16.64399568  21.75609956]   \n",
      "pred : [ 19.19130135  13.70557785  18.97570229]\n",
      "\n",
      "Iteration : 1350  loss : 2.699573516845703  \n",
      "real : [ 13.82325681  15.24819678  13.90697627]   \n",
      "pred : [ 13.27169132  13.20350742  13.21041679]\n",
      "\n",
      "Iteration : 1375  loss : 1.1869804859161377  \n",
      "real : [ 13.33848983  14.80461911  13.94727934]   \n",
      "pred : [ 15.35379791  14.6649971   14.10149384]\n",
      "\n",
      "Iteration : 1400  loss : 1.6970880031585693  \n",
      "real : [ 13.57129352  13.4672029   14.5242367 ]   \n",
      "pred : [ 15.44134998  15.95667076  14.6788702 ]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 1425  loss : 2.983933210372925  \n",
      "real : [ 11.00159483  15.3110371   13.20292248]   \n",
      "pred : [ 14.62243462  14.77546978  14.6341238 ]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7b19c4ce75ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     _,loss_,pred,summary = sess.run([train_step,loss,logits,merged],\n\u001b[0;32m---> 15\u001b[0;31m                                     feed_dict = {x : x_, y: y_})\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_iterations = 150000\n",
    "\n",
    "checkpoint_path = \"./logs/ET\"\n",
    "    \n",
    "train_writer = tf.summary.FileWriter('logs/train',\n",
    "                                    sess.graph)\n",
    "step = 0\n",
    "\n",
    "for i,(x_,y_) in enumerate(gen_data(batch_size,num_steps,n_iterations,\n",
    "                                    data,resample=resample)):\n",
    "    if(y_.shape[0] == 0):\n",
    "        continue\n",
    "\n",
    "    _,loss_,pred,summary = sess.run([train_step,loss,logits,merged],\n",
    "                                    feed_dict = {x : x_, y: y_})\n",
    "\n",
    "    if tensorboard:\n",
    "        train_writer.add_summary(summary, step)\n",
    "\n",
    "    if(i % 25 == 0):\n",
    "        print(\"Iteration : {}  loss : {}  \\nreal : {}   \\npred : {}\\n\".format(i, loss_,\n",
    "                                                                                       y_[0:3],pred[0:3]))\n",
    "    step+=1\n",
    "if save:\n",
    "    save_path = saver.save(sess, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halifax Energy Balance 5min 2013\n"
     ]
    }
   ],
   "source": [
    "for i,(x_,y_) in enumerate(gen_data(batch_size,num_steps,n_iterations,\n",
    "                                    load_data([\"Halifax\"],['2013']),resample=resample)):\n",
    "    if(x_.shape[0] == 0):\n",
    "        continue\n",
    "        \n",
    "    pred = sess.run([logits], feed_dict = {x : x_ })\n",
    "    \n",
    "    print(\"Iteration : {}  \\nreal : {}   \\npred : {}\\n\".format(i, y_[0:3],pred[0][0:3]))\n",
    "    if(i > 200):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(load_data([\"Calgary\"],['2013']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Radiation      Wind   Humidity  Lysimeter       Temp  \\\n",
      "2013-05-16 12:00:00   16.256182  1.259000  63.416364  12.874815  10.451818   \n",
      "2013-05-16 18:00:00  -49.123806  0.820819  80.275000  12.998047   7.874569   \n",
      "2013-05-17 00:00:00  -62.440694  1.786375  90.811111  13.022708   3.558889   \n",
      "2013-05-17 06:00:00  176.045694  1.313750  72.180972  13.000165   7.504472   \n",
      "2013-05-17 12:00:00  324.389722  0.763486  36.864861  15.199888  15.742361   \n",
      "2013-05-17 18:00:00  -11.024542  0.487528  37.742222  15.209717  14.858194   \n",
      "2013-05-18 00:00:00  -52.335139  1.245139  69.095417  15.183530   6.657917   \n",
      "2013-05-18 06:00:00  243.985583  1.778542  57.481944  15.141670  10.006958   \n",
      "2013-05-18 12:00:00  397.068056  2.130014  33.206667  14.951719  17.845833   \n",
      "2013-05-18 18:00:00  -20.653514  1.849778  44.300556  14.832475  14.691250   \n",
      "2013-05-19 00:00:00  -25.777000  1.316125  67.887222  14.810025   9.433556   \n",
      "2013-05-19 06:00:00   30.498292  1.157722  66.066250  14.860086  10.797028   \n",
      "2013-05-19 12:00:00  126.559444  1.284347  55.203889  14.777187  13.347361   \n",
      "2013-05-19 18:00:00   -1.670361  1.579583  54.704028  14.713149  13.178194   \n",
      "2013-05-20 00:00:00  -49.811250  2.137361  80.760556  14.694904   6.506292   \n",
      "2013-05-20 06:00:00  187.764139  1.371889  64.397917  14.665173  10.687514   \n",
      "2013-05-20 12:00:00  363.825833  1.137875  37.744444  14.520818  18.091806   \n",
      "2013-05-20 18:00:00   18.073097  2.112736  46.905972  14.389290  16.024444   \n",
      "2013-05-21 00:00:00  -48.673056  0.988958  67.515278  14.373210  11.079444   \n",
      "2013-05-21 06:00:00  221.787056  2.113639  62.315972  14.336484  12.511528   \n",
      "2013-05-21 12:00:00  451.638889  4.452694  24.737361  14.172952  19.642639   \n",
      "2013-05-21 18:00:00  -20.936736  3.371208  19.782083  14.060138  17.259444   \n",
      "2013-05-22 00:00:00  -66.045694  1.328264  33.402500  14.045567   9.907056   \n",
      "2013-05-22 06:00:00    8.944667  1.042986  63.422917  14.109599   7.365472   \n",
      "2013-05-22 12:00:00  -10.475514  1.389417  71.982917  14.279995   9.381708   \n",
      "2013-05-22 18:00:00   -7.399292  1.165014  42.391111  14.229127  13.562222   \n",
      "2013-05-23 00:00:00  -25.347444  0.929403  36.848889  14.196956  11.872222   \n",
      "2013-05-23 06:00:00   -8.706403  0.848625  60.754444  14.226792   8.435583   \n",
      "2013-05-23 12:00:00   16.145667  0.869556  93.263889  15.171172   6.083611   \n",
      "2013-05-23 18:00:00   -2.263542  1.509319  95.681944  15.945580   5.324889   \n",
      "...                         ...       ...        ...        ...        ...   \n",
      "2013-10-11 06:00:00   36.730528  0.926208  81.776250  15.267974   1.514736   \n",
      "2013-10-11 12:00:00  157.972236  0.685347  42.924583  15.124012   6.793556   \n",
      "2013-10-11 18:00:00  -23.134750  0.384319  53.630417  15.122601   5.241042   \n",
      "2013-10-12 00:00:00  -18.607083  0.994819  66.826389  15.167978   2.713236   \n",
      "2013-10-12 06:00:00   42.947806  0.426028  66.527500  15.173665   2.841028   \n",
      "2013-10-12 12:00:00  179.407639  1.517806  41.504306  15.039492   7.167736   \n",
      "2013-10-12 18:00:00  -43.921653  1.071417  49.464167  15.045764   5.012486   \n",
      "2013-10-13 00:00:00  -19.964583  0.290472  64.202083  15.071607   2.550750   \n",
      "2013-10-13 06:00:00   66.224750  0.691528  64.575694  15.109206   3.080806   \n",
      "2013-10-13 12:00:00  137.587625  0.535903  40.485972  15.004137   7.807847   \n",
      "2013-10-13 18:00:00  -25.620000  0.187764  48.711250  15.039069   5.549764   \n",
      "2013-10-14 00:00:00  -37.873333  1.446028  74.403750  15.084653   0.215486   \n",
      "2013-10-14 06:00:00   43.877222  2.289181  67.222917  15.108521  -0.278569   \n",
      "2013-10-14 12:00:00  259.359167  0.751694  29.661667  14.960801  10.627736   \n",
      "2013-10-14 18:00:00  -58.605333  0.936528  38.396944  14.964481   7.626889   \n",
      "2013-10-15 00:00:00  -56.596528  2.579472  61.396111  15.001780   0.830556   \n",
      "2013-10-15 06:00:00   37.261125  3.033750  54.130139  15.017076   3.223333   \n",
      "2013-10-15 12:00:00  196.486806  1.208556  27.431111  14.891976  15.446250   \n",
      "2013-10-15 18:00:00  -20.277014  0.295514  49.945694  14.893970  11.007917   \n",
      "2013-10-16 00:00:00  -17.407778  0.600042  89.143472  15.242830   4.775333   \n",
      "2013-10-16 06:00:00   24.457319  0.890639  82.146250  15.577438   3.732361   \n",
      "2013-10-16 12:00:00  152.573028  0.684972  52.784722  15.498505   7.044306   \n",
      "2013-10-16 18:00:00  -51.165000  0.114625  60.970000  15.515214   4.016056   \n",
      "2013-10-17 00:00:00  -23.944167  2.392750  84.164444  15.557293   0.183514   \n",
      "2013-10-17 06:00:00   29.756889  1.794972  66.115417  15.531433   3.748972   \n",
      "2013-10-17 12:00:00  173.572653  1.501792  37.928333  15.428140   8.468681   \n",
      "2013-10-17 18:00:00  -50.817778  0.734889  52.336667  15.477035   4.630319   \n",
      "2013-10-18 00:00:00  -50.951667  2.794069  74.806667  15.519539  -0.594931   \n",
      "2013-10-18 06:00:00   38.241528  2.712958  62.930556  15.504023   2.917847   \n",
      "2013-10-18 12:00:00  332.647619  1.980190  31.836667  15.417843  12.553333   \n",
      "\n",
      "                         Rain  \n",
      "2013-05-16 12:00:00   0.00000  \n",
      "2013-05-16 18:00:00   1.34947  \n",
      "2013-05-17 00:00:00   0.00000  \n",
      "2013-05-17 06:00:00   0.00000  \n",
      "2013-05-17 12:00:00   0.00000  \n",
      "2013-05-17 18:00:00   0.00000  \n",
      "2013-05-18 00:00:00   0.00000  \n",
      "2013-05-18 06:00:00   0.00000  \n",
      "2013-05-18 12:00:00   0.00000  \n",
      "2013-05-18 18:00:00   0.00000  \n",
      "2013-05-19 00:00:00   0.00000  \n",
      "2013-05-19 06:00:00   0.44480  \n",
      "2013-05-19 12:00:00   0.00000  \n",
      "2013-05-19 18:00:00   0.00000  \n",
      "2013-05-20 00:00:00   0.00000  \n",
      "2013-05-20 06:00:00   0.00000  \n",
      "2013-05-20 12:00:00   0.00000  \n",
      "2013-05-20 18:00:00   0.00000  \n",
      "2013-05-21 00:00:00   0.00000  \n",
      "2013-05-21 06:00:00   0.00000  \n",
      "2013-05-21 12:00:00   0.00000  \n",
      "2013-05-21 18:00:00   0.00000  \n",
      "2013-05-22 00:00:00   0.00000  \n",
      "2013-05-22 06:00:00   2.33520  \n",
      "2013-05-22 12:00:00   0.22240  \n",
      "2013-05-22 18:00:00   0.00000  \n",
      "2013-05-23 00:00:00   0.00000  \n",
      "2013-05-23 06:00:00   2.33520  \n",
      "2013-05-23 12:00:00  14.56720  \n",
      "2013-05-23 18:00:00   5.78240  \n",
      "...                       ...  \n",
      "2013-10-11 06:00:00   0.00000  \n",
      "2013-10-11 12:00:00   0.00000  \n",
      "2013-10-11 18:00:00   0.00000  \n",
      "2013-10-12 00:00:00   0.00000  \n",
      "2013-10-12 06:00:00   0.00000  \n",
      "2013-10-12 12:00:00   0.00000  \n",
      "2013-10-12 18:00:00   0.00000  \n",
      "2013-10-13 00:00:00   0.00000  \n",
      "2013-10-13 06:00:00   0.00000  \n",
      "2013-10-13 12:00:00   0.00000  \n",
      "2013-10-13 18:00:00   0.00000  \n",
      "2013-10-14 00:00:00   0.00000  \n",
      "2013-10-14 06:00:00   0.00000  \n",
      "2013-10-14 12:00:00   0.00000  \n",
      "2013-10-14 18:00:00   0.00000  \n",
      "2013-10-15 00:00:00   0.00000  \n",
      "2013-10-15 06:00:00   0.00000  \n",
      "2013-10-15 12:00:00   0.00000  \n",
      "2013-10-15 18:00:00   0.00000  \n",
      "2013-10-16 00:00:00   6.11600  \n",
      "2013-10-16 06:00:00   0.11120  \n",
      "2013-10-16 12:00:00   0.00000  \n",
      "2013-10-16 18:00:00   0.00000  \n",
      "2013-10-17 00:00:00   0.00000  \n",
      "2013-10-17 06:00:00   0.00000  \n",
      "2013-10-17 12:00:00   0.00000  \n",
      "2013-10-17 18:00:00   0.00000  \n",
      "2013-10-18 00:00:00   0.00000  \n",
      "2013-10-18 06:00:00   0.00000  \n",
      "2013-10-18 12:00:00   0.00000  \n",
      "\n",
      "[610 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
