{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from load_data import gen_data,load_data,standardize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "num_steps = 200\n",
    "\n",
    "\n",
    "input_num = 5\n",
    "output_num = 1\n",
    "\n",
    "state_size = 80\n",
    "\n",
    "num_layers = 6\n",
    "\n",
    "def lrelu(x, name, leak=0.2): \n",
    "    #return tf.maximum(x, leak * x, name=name) \n",
    "    return tf.maximum(x, 0, name=name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, [None, num_steps,input_num], name='input_placeholder')\n",
    "y = tf.placeholder(tf.float32, [None], name='labels_placeholder')\n",
    "\n",
    "keep_prob = tf.placeholder_with_default(1.0, shape=())\n",
    "\n",
    "#is_train = tf.placeholder_with_default(False, shape=())\n",
    "\n",
    "x_reshaped = tf.reshape(x,[tf.shape(x)[0],x.shape[1],1,x.shape[2]])\n",
    "\n",
    "\n",
    "rnn_inputs = tf.squeeze(x_reshaped,axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape:0\", shape=(?, 200, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(x_reshaped)\n",
    "#print(conv1)\n",
    "#print(conv2)\n",
    "#print(pool1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "cells = []\n",
    "for i in range(0, num_layers):\n",
    "    cell = tf.contrib.rnn.LSTMCell(state_size )\n",
    "    cell = tf.contrib.rnn.DropoutWrapper(cell, output_keep_prob=keep_prob)\n",
    "    cells.append(cell)\n",
    "    \n",
    "mul_cell = tf.nn.rnn_cell.MultiRNNCell(cells)\n",
    "\n",
    "rnn_outputs, final_state = tf.nn.dynamic_rnn(mul_cell, rnn_inputs, dtype=tf.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_outputs_reshaped = tf.reshape(rnn_outputs,[tf.shape(rnn_outputs)[0],\n",
    "                                               rnn_outputs.shape[1],1,rnn_outputs.shape[2]])\n",
    "\n",
    "#############################################################\n",
    "\n",
    "conv5 = lrelu(tf.layers.conv2d(rnn_outputs_reshaped, name=\"conv5\", filters = 64, \n",
    "                         kernel_size = [4,1],strides = [1,1],padding = \"valid\", activation = None),\"conv5_lrelu\")\n",
    "#bn1 = tf.layers.batch_normalization(conv5, training = is_train)\n",
    "\n",
    "conv6 = lrelu(tf.layers.conv2d(conv5, name=\"conv6\", filters = 128, \n",
    "                         kernel_size = [4,1],strides = [1,1],padding = \"valid\", activation = None),\"conv6_lrelu\")\n",
    "#bn2 = tf.layers.batch_normalization(conv6, training = is_train)\n",
    "\n",
    "pool3 = tf.layers.max_pooling2d(inputs=conv6, name = \"pool3\", pool_size=[2, 1], strides=[2,1])\n",
    "\n",
    "#############################################################\n",
    "\n",
    "conv7 = lrelu(tf.layers.conv2d(pool3, name=\"conv7\", filters = 64, \n",
    "                         kernel_size = [4,1],strides = [1,1],padding = \"valid\", activation = None),\"conv7_lrelu\")\n",
    "#bn3 = tf.layers.batch_normalization(conv7, training = is_train)\n",
    "\n",
    "\n",
    "conv8 = lrelu(tf.layers.conv2d(conv7, name=\"conv8\", filters = 128, \n",
    "                         kernel_size = [4,1],strides = [1,1],padding = \"valid\", activation = None),\"conv8_lrelu\")\n",
    "#bn4 = tf.layers.batch_normalization(conv8, training = is_train)\n",
    "\n",
    "\n",
    "pool4 = tf.layers.max_pooling2d(inputs=conv8, name = \"pool4\", pool_size=[2, 1], strides=[2,1])\n",
    "\n",
    "#############################################################\n",
    "\n",
    "conv9 = lrelu(tf.layers.conv2d(pool4, name=\"conv9\", filters = 32, \n",
    "                         kernel_size = [4,1],strides = [1,1],padding = \"valid\", activation = None),\"conv9_lrelu\")\n",
    "#bn5 = tf.layers.batch_normalization(conv9, training = is_train)\n",
    "\n",
    "\n",
    "conv10 = lrelu(tf.layers.conv2d(conv9, name=\"conv10\", filters = 64, \n",
    "                         kernel_size = [4,1],strides = [1,1],padding = \"valid\", activation = None),\"conv10_lrelu\")\n",
    "#bn6 = tf.layers.batch_normalization(conv10, training = is_train)\n",
    "\n",
    "\n",
    "\n",
    "pool5 = tf.layers.max_pooling2d(inputs=conv10, name = \"pool5\", pool_size=[2, 1], strides=[2,1])\n",
    "\n",
    "#############################################################\n",
    "\n",
    "pool5_flat = tf.reshape(pool5,[tf.shape(pool5)[0],pool5.shape[1]*pool5.shape[2]*pool5.shape[3]])\n",
    "\n",
    "\n",
    "#rnn_outputs_flat = tf.reshape(rnn_outputs,[tf.shape(rnn_outputs)[0],rnn_outputs.shape[1]*rnn_outputs.shape[2]])\n",
    "dense1 = tf.layers.dense(pool5_flat,512,name=\"dense1\")\n",
    "dense2 = tf.layers.dense(dense1,output_num,name=\"dense2\")\n",
    "\n",
    "logits = tf.squeeze(dense2,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_1:0\", shape=(?, 200, 1, 80), dtype=float32)\n",
      " \n",
      "Tensor(\"conv5_lrelu:0\", shape=(?, 197, 1, 64), dtype=float32)\n",
      "Tensor(\"conv6_lrelu:0\", shape=(?, 194, 1, 128), dtype=float32)\n",
      "Tensor(\"pool3/MaxPool:0\", shape=(?, 97, 1, 128), dtype=float32)\n",
      " \n",
      "Tensor(\"conv7_lrelu:0\", shape=(?, 94, 1, 64), dtype=float32)\n",
      "Tensor(\"conv8_lrelu:0\", shape=(?, 91, 1, 128), dtype=float32)\n",
      "Tensor(\"pool4/MaxPool:0\", shape=(?, 45, 1, 128), dtype=float32)\n",
      " \n",
      "Tensor(\"conv9_lrelu:0\", shape=(?, 42, 1, 32), dtype=float32)\n",
      "Tensor(\"conv10_lrelu:0\", shape=(?, 39, 1, 64), dtype=float32)\n",
      " \n",
      "Tensor(\"dense1/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "Tensor(\"dense2/BiasAdd:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(rnn_outputs_reshaped)\n",
    "print(\" \")\n",
    "print(conv5)\n",
    "print(conv6)\n",
    "print(pool3)\n",
    "print(\" \")\n",
    "print(conv7)\n",
    "print(conv8)\n",
    "print(pool4)\n",
    "print(\" \")\n",
    "print(conv9)\n",
    "print(conv10)\n",
    "\n",
    "print(\" \")\n",
    "print(dense1)\n",
    "print(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y - logits))\n",
    "loss_sum = tf.summary.scalar('Loss', loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.0005)\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    train_step = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./logs/ET\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 50\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "saver = tf.train.Saver()\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "\n",
    "checkpoint_path = \"./logs/ET\"\n",
    "\n",
    "\n",
    "resample=\"2H\"\n",
    "\n",
    "restore_checkpoint = True\n",
    "save = True\n",
    "tensorboard = True\n",
    "\n",
    "\n",
    "if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "    saver.restore(sess, checkpoint_path)\n",
    "else:\n",
    "    sess.run(init)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!rm -r logs/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calgary Energy Balance 5min 2013\n",
      "Calgary Water Balance 5min 2013\n",
      "Calgary Lysimeters kg 5min2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/Recurrent/load_data.py:77: FutureWarning: how in .resample() is deprecated\n",
      "the new syntax is .resample(...)..apply(<func>)\n",
      "  'Wind': \"mean\",'Rain': \"sum\",'Lysimeter': \"mean\"})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London Energy Balance 5min 2013\n",
      "London Water Balance 5min 2013\n",
      "London Lysimeters kg 5min2013\n",
      "Calgary Energy Balance 5min 2014\n",
      "Calgary Water Balance 5min 2014\n",
      "Calgary Lysimeters kg 5min2014\n",
      "London Energy Balance 5min 2014\n",
      "London Water Balance 5min 2014\n",
      "London Lysimeters kg 5min2014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/indexes/base.py:2245: FutureWarning: In the future, 'NAT < x' and 'x < NAT' will always be False.\n",
      "  self._values[0] < other_diff[0]\n"
     ]
    }
   ],
   "source": [
    "train_data = load_data([\"Calgary\",\"London\"],['2013','2014'],resample=resample)\n",
    "#train_data = load_data([\"Calgary\"],['2013'],resample=resample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Step : 305  loss : 1.6935381889343262  \n",
      "real : [ 13.80039715  13.28622225  14.17285577]   \n",
      "pred : [ 14.24129486  14.72443199  15.81780529]\n",
      "\n",
      "Step : 330  loss : 1.786769986152649  \n",
      "real : [ 13.51470258  12.69311935  14.49088509]   \n",
      "pred : [ 14.15196705  14.47507     13.13553524]\n",
      "\n",
      "Step : 355  loss : 1.2188788652420044  \n",
      "real : [ 13.74983534  14.94982163  14.53816804]   \n",
      "pred : [ 16.25978088  14.57476902  14.03418255]\n",
      "\n",
      "Step : 380  loss : 1.1408065557479858  \n",
      "real : [ 13.87609326  14.94982163  13.83672573]   \n",
      "pred : [ 11.99589634  14.1658268   14.20752811]\n",
      "\n",
      "Step : 405  loss : 1.1241989135742188  \n",
      "real : [ 16.58208551  16.36495299  14.54740456]   \n",
      "pred : [ 17.166008    15.74359894  14.23041534]\n",
      "\n",
      "Step : 430  loss : 1.7005789279937744  \n",
      "real : [ 13.05425467  13.84057768  16.63374733]   \n",
      "pred : [ 13.10794735  14.04120541  13.85040379]\n",
      "\n",
      "Step : 455  loss : 1.282101035118103  \n",
      "real : [ 13.42587556  15.77186615  17.87278166]   \n",
      "pred : [ 15.09550762  15.08304691  19.8351078 ]\n",
      "\n",
      "Step : 480  loss : 0.910584568977356  \n",
      "real : [ 16.21735662  15.88470205  15.49280333]   \n",
      "pred : [ 16.51105881  15.57614899  15.48835278]\n",
      "\n",
      "Step : 505  loss : 1.0765477418899536  \n",
      "real : [ 15.98648422  13.06740278  16.85078546]   \n",
      "pred : [ 14.40988541  14.73283863  15.07700539]\n",
      "\n",
      "Step : 530  loss : 1.5822758674621582  \n",
      "real : [ 14.04516798  13.69089562  16.2320322 ]   \n",
      "pred : [ 14.40586185  14.24036407  15.84622955]\n",
      "\n",
      "Step : 555  loss : 0.8239786028862  \n",
      "real : [ 14.3134742   13.14089167  17.14037446]   \n",
      "pred : [ 13.10271072  12.2384119   16.08876991]\n",
      "\n",
      "Step : 580  loss : 1.3627102375030518  \n",
      "real : [ 15.11770679  16.41549911  14.74804357]   \n",
      "pred : [ 14.4918642   15.27825165  13.53760338]\n",
      "\n",
      "Step : 605  loss : 1.1614845991134644  \n",
      "real : [ 12.79780862  13.19953512  13.49284091]   \n",
      "pred : [ 13.46031284  14.45091438  14.57826805]\n",
      "\n",
      "Step : 630  loss : 0.938185453414917  \n",
      "real : [ 13.12433427  14.38632319  15.25308638]   \n",
      "pred : [ 13.59205246  14.98368168  16.47317505]\n",
      "\n",
      "Step : 655  loss : 0.9223569631576538  \n",
      "real : [ 16.79442308  12.31936591  15.69273425]   \n",
      "pred : [ 16.4976902   13.40141392  15.53993607]\n",
      "\n",
      "Step : 680  loss : 1.00947904586792  \n",
      "real : [ 16.23944873  13.80139557  13.28522375]   \n",
      "pred : [ 16.65222359  15.6371603   14.93642044]\n",
      "\n",
      "Step : 705  loss : 0.9409425258636475  \n",
      "real : [ 18.49527403  13.00159486  15.46931451]   \n",
      "pred : [ 16.73679161  12.84616661  15.53506279]\n",
      "\n",
      "Step : 730  loss : 1.1921591758728027  \n",
      "real : [ 16.75244046  16.35900396  15.15242323]   \n",
      "pred : [ 15.48954391  14.94186687  14.84644508]\n",
      "\n",
      "Step : 755  loss : 1.2282336950302124  \n",
      "real : [ 14.95584976  21.86095     16.61223667]   \n",
      "pred : [ 15.49319839  19.807024    16.33120918]\n",
      "\n",
      "Step : 780  loss : 0.8548961877822876  \n",
      "real : [ 13.68847427  16.43886757  13.2127411 ]   \n",
      "pred : [ 14.38272572  15.11784172  12.45674229]\n",
      "\n",
      "Step : 805  loss : 1.0495983362197876  \n",
      "real : [ 15.41396806  14.02051457  14.34808569]   \n",
      "pred : [ 16.44813156  14.11637974  13.93869019]\n",
      "\n",
      "Step : 830  loss : 1.3939528465270996  \n",
      "real : [ 12.26654436  12.36650073  13.88626829]   \n",
      "pred : [ 12.70423889  12.65018272  16.17152214]\n",
      "\n",
      "Step : 855  loss : 1.2337661981582642  \n",
      "real : [ 19.92574567  13.82833607  17.56378709]   \n",
      "pred : [ 19.08785629  14.19997406  18.79392624]\n",
      "\n",
      "Step : 880  loss : 1.0064526796340942  \n",
      "real : [ 16.08562069  13.00734689  15.54109002]   \n",
      "pred : [ 15.00591087  12.97535896  14.89332199]\n",
      "\n",
      "Step : 905  loss : 0.9445754885673523  \n",
      "real : [ 16.12545329  13.33084329  13.78896765]   \n",
      "pred : [ 16.07896614  13.87208462  15.15786457]\n",
      "\n",
      "Step : 930  loss : 1.0772045850753784  \n",
      "real : [ 13.69645664  13.44167101  16.5596958 ]   \n",
      "pred : [ 15.18729877  13.58513451  16.66711617]\n",
      "\n",
      "Step : 955  loss : 0.9521885514259338  \n",
      "real : [ 14.83223413  16.57525682  16.57790135]   \n",
      "pred : [ 15.36977673  15.8678894   15.11708832]\n",
      "\n",
      "Step : 980  loss : 0.9197143316268921  \n",
      "real : [ 16.15655338  11.99332194  18.43393108]   \n",
      "pred : [ 13.49510098  12.70017052  18.3192482 ]\n",
      "\n",
      "Step : 1005  loss : 0.7944204211235046  \n",
      "real : [ 15.43896685  14.27477134  16.41076487]   \n",
      "pred : [ 14.77171516  14.08706093  16.10954475]\n",
      "\n",
      "Step : 1030  loss : 1.1068241596221924  \n",
      "real : [ 14.51108541  15.12105549  16.34244167]   \n",
      "pred : [ 13.58621693  15.00619125  15.78329563]\n",
      "\n",
      "Step : 1055  loss : 1.2054511308670044  \n",
      "real : [ 13.46210945  16.49139119  15.70458981]   \n",
      "pred : [ 14.27104568  13.4749651   14.71619987]\n",
      "\n",
      "Step : 1080  loss : 0.9207130670547485  \n",
      "real : [ 13.04959861  13.18962325  12.52905941]   \n",
      "pred : [ 13.51408863  13.44238949  13.51548195]\n",
      "\n",
      "Step : 1105  loss : 1.2923774719238281  \n",
      "real : [ 12.40520778  15.60566899  13.91856724]   \n",
      "pred : [ 13.75610161  16.39562607  15.23877525]\n",
      "\n",
      "Step : 1130  loss : 1.1474632024765015  \n",
      "real : [ 13.0921546   12.250326    16.16837821]   \n",
      "pred : [ 12.36334229  12.62311745  14.82508564]\n",
      "\n",
      "Step : 1155  loss : 1.0835164785385132  \n",
      "real : [ 16.42479846  14.32830965  13.55594462]   \n",
      "pred : [ 15.89250278  13.8789711   14.90235329]\n",
      "\n",
      "Step : 1180  loss : 0.8808857202529907  \n",
      "real : [ 11.86330324  17.48466119  16.10682292]   \n",
      "pred : [ 12.42739105  18.80490112  16.09352303]\n",
      "\n",
      "Step : 1205  loss : 1.0630336999893188  \n",
      "real : [ 13.57069898  13.37007009  13.25538079]   \n",
      "pred : [ 14.45524311  13.97744942  12.76260376]\n",
      "\n",
      "Step : 1230  loss : 0.74908846616745  \n",
      "real : [ 14.21190621  14.96872548  13.95846157]   \n",
      "pred : [ 13.554986    15.76496887  14.17930412]\n",
      "\n",
      "Step : 1255  loss : 1.21845281124115  \n",
      "real : [ 13.72188069  13.8687776   12.49011278]   \n",
      "pred : [ 14.70702839  13.13787937  13.43431664]\n",
      "\n",
      "Step : 1280  loss : 0.6849719882011414  \n",
      "real : [ 16.57238032  16.32469628  15.54208075]   \n",
      "pred : [ 14.44731903  16.62988853  14.34337139]\n",
      "\n",
      "Step : 1305  loss : 0.6940917372703552  \n",
      "real : [ 14.94651051  15.15109292  14.15782669]   \n",
      "pred : [ 16.8717804   15.27816391  15.7658596 ]\n",
      "\n",
      "Step : 1330  loss : 0.7671388983726501  \n",
      "real : [ 18.03900984  13.03364582  13.74927842]   \n",
      "pred : [ 18.49162292  13.74601269  14.27719307]\n",
      "\n",
      "Step : 1355  loss : 1.1948689222335815  \n",
      "real : [ 12.9774994   14.15454528  17.09854078]   \n",
      "pred : [ 13.74740887  14.24639606  16.51909256]\n",
      "\n",
      "Step : 1380  loss : 0.8547981977462769  \n",
      "real : [ 13.08897951  14.62068922  14.79389605]   \n",
      "pred : [ 13.01474476  14.81277657  15.06549835]\n",
      "\n",
      "Step : 1405  loss : 1.295619249343872  \n",
      "real : [ 15.08761668  13.69639864  13.50095185]   \n",
      "pred : [ 15.33922291  14.47987175  14.08479118]\n",
      "\n",
      "Step : 1430  loss : 1.367793321609497  \n",
      "real : [ 17.04404301  15.47664207  14.30026411]   \n",
      "pred : [ 17.27902985  16.3134079   14.71971893]\n",
      "\n",
      "Step : 1455  loss : 1.9412689208984375  \n",
      "real : [ 13.81150134  13.63527196  14.4608682 ]   \n",
      "pred : [ 14.81576252  15.01521873  14.09685898]\n",
      "\n",
      "Step : 1480  loss : 1.5124354362487793  \n",
      "real : [ 13.75157182  14.80419239  13.45941911]   \n",
      "pred : [ 14.09918213  14.57320023  16.05332184]\n",
      "\n",
      "Step : 1505  loss : 0.8345868587493896  \n",
      "real : [ 15.81399596  16.61223667  14.33089947]   \n",
      "pred : [ 15.25407791  15.97306728  14.27020454]\n",
      "\n",
      "Step : 1530  loss : 1.926611304283142  \n",
      "real : [ 18.3421587   13.64353589  12.42225533]   \n",
      "pred : [ 16.69543457  14.26564503  12.33508587]\n",
      "\n",
      "Step : 1555  loss : 0.9368739128112793  \n",
      "real : [ 12.66973401  15.14492756  16.64576301]   \n",
      "pred : [ 13.14415169  12.66440773  15.48703289]\n",
      "\n",
      "Step : 1580  loss : 0.7820003032684326  \n",
      "real : [ 13.89562653  15.05574209  13.17107313]   \n",
      "pred : [ 14.09977341  15.02184868  14.24290943]\n",
      "\n",
      "Step : 1605  loss : 0.6647081971168518  \n",
      "real : [ 12.90230884  17.24329325  16.74015506]   \n",
      "pred : [ 13.41033173  16.19545746  16.30338287]\n",
      "\n",
      "Step : 1630  loss : 1.079489827156067  \n",
      "real : [ 15.02978445  16.99659687  13.12730045]   \n",
      "pred : [ 16.40879631  19.058918    14.94747353]\n",
      "\n",
      "Step : 1655  loss : 0.9808225035667419  \n",
      "real : [ 13.51793117  14.51392421  13.03250578]   \n",
      "pred : [ 13.86575603  13.2510004   12.96604061]\n",
      "\n",
      "Step : 1680  loss : 0.9412069916725159  \n",
      "real : [ 14.91789321  12.99328904  13.18089894]   \n",
      "pred : [ 16.1462059   12.74590302  13.39772511]\n",
      "\n",
      "Step : 1705  loss : 0.6944339871406555  \n",
      "real : [ 15.48294588  11.69652749  16.85630248]   \n",
      "pred : [ 15.98604965  12.3603754   18.88487434]\n",
      "\n",
      "Step : 1730  loss : 1.054824709892273  \n",
      "real : [ 15.89887436  13.97713974  14.15235331]   \n",
      "pred : [ 13.62844944  13.1205883   14.81542015]\n",
      "\n",
      "Step : 1755  loss : 0.9920908212661743  \n",
      "real : [ 13.45981565  13.59877516  14.040173  ]   \n",
      "pred : [ 13.63882351  14.33125687  14.41326618]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 1780  loss : 1.581230640411377  \n",
      "real : [ 14.3347991   16.25761073  16.89113722]   \n",
      "pred : [ 15.62805557  17.24364853  18.80257988]\n",
      "\n",
      "Step : 1805  loss : 1.1559019088745117  \n",
      "real : [ 13.91729268  15.236389    13.96186072]   \n",
      "pred : [ 14.34927177  14.78631783  16.1844101 ]\n",
      "\n",
      "Step : 1830  loss : 1.7097136974334717  \n",
      "real : [ 16.64130248  18.10884879  13.85844381]   \n",
      "pred : [ 16.90582085  20.73955536  14.56625557]\n",
      "\n",
      "Step : 1855  loss : 1.8379144668579102  \n",
      "real : [ 14.18026525  17.06570675  17.08401   ]   \n",
      "pred : [ 15.60383797  17.42197418  17.36881256]\n",
      "\n",
      "Step : 1880  loss : 0.4763198792934418  \n",
      "real : [ 12.20486296  16.46449382  11.72763694]   \n",
      "pred : [ 11.8552618   15.39483356  12.58041382]\n",
      "\n",
      "Step : 1905  loss : 0.4967728555202484  \n",
      "real : [ 11.85515097  14.44469619  15.42900869]   \n",
      "pred : [ 12.81297016  15.66137695  16.04311752]\n",
      "\n",
      "Step : 1930  loss : 1.0006077289581299  \n",
      "real : [ 16.90658228  14.20644302  17.5498564 ]   \n",
      "pred : [ 15.99274921  15.60336208  18.00540924]\n",
      "\n",
      "Step : 1955  loss : 1.0269227027893066  \n",
      "real : [ 17.56731545  13.69986437  13.3303323 ]   \n",
      "pred : [ 17.29151535  13.19000721  13.01049232]\n",
      "\n",
      "Step : 1980  loss : 0.5679154992103577  \n",
      "real : [ 13.00198216  13.15453455  13.52936556]   \n",
      "pred : [ 13.06062126  13.45308685  13.20399094]\n",
      "\n",
      "Step : 2005  loss : 1.4206509590148926  \n",
      "real : [ 16.89789676  14.43066362  13.81978698]   \n",
      "pred : [ 18.13145828  14.99763298  16.02659416]\n",
      "\n",
      "Step : 2030  loss : 0.8636814951896667  \n",
      "real : [ 13.9736066   18.14395998  13.69990688]   \n",
      "pred : [ 14.22931194  19.50192451  13.96203613]\n",
      "\n",
      "Step : 2055  loss : 1.1180037260055542  \n",
      "real : [ 16.81615696  19.13380899  16.32039291]   \n",
      "pred : [ 15.6086092   18.70221901  15.8070879 ]\n",
      "\n",
      "Step : 2080  loss : 1.07166588306427  \n",
      "real : [ 13.6970667   17.92975461  13.46097007]   \n",
      "pred : [ 14.80014515  16.77610397  13.20769596]\n",
      "\n",
      "Step : 2105  loss : 0.9678165912628174  \n",
      "real : [ 16.87973238  13.97765514  13.52810353]   \n",
      "pred : [ 17.19179726  14.80148125  15.44882202]\n",
      "\n",
      "Step : 2130  loss : 1.8386468887329102  \n",
      "real : [ 18.87738984  15.73637502  13.48086338]   \n",
      "pred : [ 21.16419029  17.11117744  13.72306442]\n",
      "\n",
      "Step : 2155  loss : 0.7740147113800049  \n",
      "real : [ 14.44943113  16.94378079  16.5604534 ]   \n",
      "pred : [ 14.01516533  16.95095444  17.21172714]\n",
      "\n",
      "Step : 2180  loss : 0.6913716793060303  \n",
      "real : [ 13.84256896  14.0263439   18.44502956]   \n",
      "pred : [ 14.11182785  15.15070343  19.75899315]\n",
      "\n",
      "Step : 2205  loss : 0.8337623476982117  \n",
      "real : [ 15.54208075  18.35502953  16.81886765]   \n",
      "pred : [ 14.6736021   16.70207214  16.3810463 ]\n",
      "\n",
      "Step : 2230  loss : 1.4973715543746948  \n",
      "real : [ 14.01781651  14.5894582   14.58803912]   \n",
      "pred : [ 13.13979626  13.29298973  12.93753147]\n",
      "\n",
      "Step : 2255  loss : 0.7786436676979065  \n",
      "real : [ 13.55857188  14.96265337  16.88630173]   \n",
      "pred : [ 13.11912537  13.65427399  16.74154472]\n",
      "\n",
      "Step : 2280  loss : 0.583514392375946  \n",
      "real : [ 17.16011622  16.72874267  17.01602032]   \n",
      "pred : [ 15.9474659   16.75821114  17.17503357]\n",
      "\n",
      "Step : 2305  loss : 0.7839494347572327  \n",
      "real : [ 15.83560218  15.62589719  14.87055846]   \n",
      "pred : [ 16.09523964  15.892416    13.57959175]\n",
      "\n",
      "Step : 2330  loss : 0.9600977897644043  \n",
      "real : [ 12.63191638  15.88107603  19.027921  ]   \n",
      "pred : [ 13.55974007  15.78161144  19.99660873]\n",
      "\n",
      "Step : 2355  loss : 0.7860698103904724  \n",
      "real : [ 14.58721187  16.84650375  16.57683946]   \n",
      "pred : [ 13.35000134  16.77583122  15.94625187]\n",
      "\n",
      "Step : 2380  loss : 0.6824078559875488  \n",
      "real : [ 18.66987041  18.74226128  16.45937703]   \n",
      "pred : [ 19.56864166  18.88059425  15.35447979]\n",
      "\n",
      "Step : 2405  loss : 0.6423032283782959  \n",
      "real : [ 16.8692299   17.00455005  17.11320552]   \n",
      "pred : [ 16.86452675  16.78165245  17.21383858]\n",
      "\n",
      "Step : 2430  loss : 0.6891921162605286  \n",
      "real : [ 17.23356711  15.4663407   15.47259783]   \n",
      "pred : [ 16.6730938   13.87542629  14.2764883 ]\n",
      "\n",
      "Step : 2455  loss : 0.5561556220054626  \n",
      "real : [ 11.98920999  14.52580348  13.13885216]   \n",
      "pred : [ 11.77793789  15.1379776   13.93664074]\n",
      "\n",
      "Step : 2480  loss : 0.8751959800720215  \n",
      "real : [ 16.2477414   16.88183172  16.82720615]   \n",
      "pred : [ 16.17710876  16.4538765   16.93422508]\n",
      "\n",
      "Step : 2505  loss : 0.6609798669815063  \n",
      "real : [ 16.64864352  15.24220887  13.06351307]   \n",
      "pred : [ 15.68486023  14.88395309  13.77227497]\n",
      "\n",
      "Step : 2530  loss : 0.583595871925354  \n",
      "real : [ 13.15510387  12.92895398  13.58898443]   \n",
      "pred : [ 13.07313538  13.52120495  14.65096188]\n",
      "\n",
      "Step : 2555  loss : 0.4945083558559418  \n",
      "real : [ 13.88626829  14.9680302   17.45431698]   \n",
      "pred : [ 15.48954105  13.98316574  17.97988319]\n",
      "\n",
      "Step : 2580  loss : 0.8870459198951721  \n",
      "real : [ 12.19768338  16.51799649  13.62629144]   \n",
      "pred : [ 12.31130219  16.44758034  14.23298073]\n",
      "\n",
      "Step : 2605  loss : 0.547316312789917  \n",
      "real : [ 13.17846688  13.42176666  13.71358812]   \n",
      "pred : [ 13.3214159   13.76369667  13.2337122 ]\n",
      "\n",
      "Step : 2630  loss : 0.9640361070632935  \n",
      "real : [ 16.05159223  17.03568272  15.40098869]   \n",
      "pred : [ 16.43087387  16.45825577  16.25744629]\n",
      "\n",
      "Step : 2655  loss : 0.8224055767059326  \n",
      "real : [ 14.38113516  13.04937175  12.53009348]   \n",
      "pred : [ 14.05831337  13.91878223  13.05697727]\n",
      "\n",
      "Step : 2680  loss : 0.5006356239318848  \n",
      "real : [ 13.80039715  14.31980716  16.3418735 ]   \n",
      "pred : [ 14.46488857  13.50613689  16.11654854]\n",
      "\n",
      "Step : 2705  loss : 0.8117406964302063  \n",
      "real : [ 14.14640674  15.08199478  13.54534895]   \n",
      "pred : [ 15.91531277  14.68768024  13.01000881]\n",
      "\n",
      "Step : 2730  loss : 0.5630135536193848  \n",
      "real : [ 18.50114395  13.01131606  16.54872588]   \n",
      "pred : [ 19.91687202  13.38869286  16.38013649]\n",
      "\n",
      "Step : 2755  loss : 0.5643615126609802  \n",
      "real : [ 16.56826396  14.3540418   14.8388587 ]   \n",
      "pred : [ 16.04242897  14.38420486  14.41488457]\n",
      "\n",
      "Step : 2780  loss : 0.7506324648857117  \n",
      "real : [ 12.5161768   13.361178    13.07026862]   \n",
      "pred : [ 12.9966917   14.33752537  14.06720829]\n",
      "\n",
      "Step : 2805  loss : 0.8489280939102173  \n",
      "real : [ 14.25514625  16.36261372  13.72110905]   \n",
      "pred : [ 15.87076569  15.34954739  13.72596931]\n",
      "\n",
      "Step : 2830  loss : 0.8425557017326355  \n",
      "real : [ 15.21801299  14.2905871   14.19077826]   \n",
      "pred : [ 13.42317677  13.25595188  13.58820343]\n",
      "\n",
      "Step : 2855  loss : 1.149255394935608  \n",
      "real : [ 18.43132099  17.01270241  12.26656793]   \n",
      "pred : [ 20.31919861  17.10454369  13.35478306]\n",
      "\n",
      "Step : 2880  loss : 0.6410950422286987  \n",
      "real : [ 13.7522583   17.08567966  14.40150253]   \n",
      "pred : [ 14.61647987  16.83979988  14.35717297]\n",
      "\n",
      "Step : 2905  loss : 0.49432769417762756  \n",
      "real : [ 16.88675656  17.17987719  16.97039615]   \n",
      "pred : [ 16.59644508  15.79142475  16.14817429]\n",
      "\n",
      "Step : 2930  loss : 0.3776884973049164  \n",
      "real : [ 16.91705786  16.7259268   17.06692935]   \n",
      "pred : [ 16.77130318  17.06610107  16.99527359]\n",
      "\n",
      "Step : 2955  loss : 0.4355226755142212  \n",
      "real : [ 14.14369626  13.40617225  13.15389164]   \n",
      "pred : [ 14.23559666  14.11932468  13.32260323]\n",
      "\n",
      "Step : 2980  loss : 0.8407276272773743  \n",
      "real : [ 17.16088253  13.76756361  16.7849453 ]   \n",
      "pred : [ 16.01787758  14.00269413  18.25555229]\n",
      "\n",
      "Step : 3005  loss : 0.8352134823799133  \n",
      "real : [ 12.35642563  14.60288619  18.24997806]   \n",
      "pred : [ 12.0747757   16.03495789  17.92078018]\n",
      "\n",
      "Step : 3030  loss : 0.6598504781723022  \n",
      "real : [ 14.72197426  15.0435095   14.61705745]   \n",
      "pred : [ 14.35528946  13.94606209  13.60306168]\n",
      "\n",
      "Step : 3055  loss : 0.5429551005363464  \n",
      "real : [ 13.2867551   16.52477492  17.87493777]   \n",
      "pred : [ 15.49302006  16.61804962  17.58879471]\n",
      "\n",
      "Step : 3080  loss : 0.6665197610855103  \n",
      "real : [ 13.68239367  14.1112754   15.50146914]   \n",
      "pred : [ 14.8479538   15.07111263  16.11950302]\n",
      "\n",
      "Step : 3105  loss : 0.72682785987854  \n",
      "real : [ 12.94067388  16.83273943  13.67867851]   \n",
      "pred : [ 14.12208366  16.69927216  15.41495705]\n",
      "\n",
      "Step : 3130  loss : 0.49418938159942627  \n",
      "real : [ 15.43660813  14.30479267  16.30971378]   \n",
      "pred : [ 15.99198341  15.34764957  16.31697845]\n",
      "\n",
      "Step : 3155  loss : 0.48832938075065613  \n",
      "real : [ 14.50805198  21.06220667  16.42302629]   \n",
      "pred : [ 14.57879734  19.8047142   16.00829124]\n",
      "\n",
      "Step : 3180  loss : 0.424468457698822  \n",
      "real : [ 13.20697603  18.68471207  13.64353589]   \n",
      "pred : [ 13.24467659  18.28040886  14.15513325]\n",
      "\n",
      "Step : 3205  loss : 1.0111163854599  \n",
      "real : [ 17.05260019  13.80079112  15.63969819]   \n",
      "pred : [ 16.00302505  14.06126118  14.70825005]\n",
      "\n",
      "Step : 3230  loss : 0.4839344322681427  \n",
      "real : [ 16.79965181  13.72624736  14.09539025]   \n",
      "pred : [ 15.73365116  13.53891659  14.19430828]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 3255  loss : 0.42013514041900635  \n",
      "real : [ 13.06689968  19.19831504  12.94067806]   \n",
      "pred : [ 13.24608135  19.50259018  12.93791008]\n",
      "\n",
      "Step : 3280  loss : 0.8928426504135132  \n",
      "real : [ 16.98074216  14.32999451  16.78193019]   \n",
      "pred : [ 15.91061497  13.85345268  16.12127304]\n",
      "\n",
      "Step : 3305  loss : 0.25822436809539795  \n",
      "real : [ 16.6024655   15.55913114  18.78673733]   \n",
      "pred : [ 15.87665749  15.36419201  19.17637825]\n",
      "\n",
      "Step : 3330  loss : 0.6152482628822327  \n",
      "real : [ 17.1213269   13.52350048  16.86246992]   \n",
      "pred : [ 17.97829247  13.02054787  16.16657448]\n",
      "\n",
      "Step : 3355  loss : 0.6659210324287415  \n",
      "real : [ 14.29039504  12.69311935  13.22052926]   \n",
      "pred : [ 14.62173271  13.45103741  13.41719246]\n",
      "\n",
      "Step : 3380  loss : 0.518602728843689  \n",
      "real : [ 14.28778234  12.67614317  16.33375439]   \n",
      "pred : [ 14.71456051  12.89746761  15.53874302]\n",
      "\n",
      "Step : 3405  loss : 0.3007011413574219  \n",
      "real : [ 15.75426026  15.87905365  13.68743177]   \n",
      "pred : [ 16.52566719  16.28069878  14.37947845]\n",
      "\n",
      "Step : 3430  loss : 0.719736635684967  \n",
      "real : [ 16.54780701  13.36256051  13.46097007]   \n",
      "pred : [ 16.19028282  13.57134914  14.00572777]\n",
      "\n",
      "Step : 3455  loss : 0.4419150948524475  \n",
      "real : [ 13.94597283  16.18461293  13.66917231]   \n",
      "pred : [ 13.14525604  15.09798813  14.34056282]\n",
      "\n",
      "Step : 3480  loss : 0.4901023805141449  \n",
      "real : [ 16.8692299   16.88630173  11.86439585]   \n",
      "pred : [ 16.83572197  16.55678368  12.26537514]\n",
      "\n",
      "Step : 3505  loss : 0.7118496894836426  \n",
      "real : [ 18.81118729  15.3549581   13.69109909]   \n",
      "pred : [ 18.94935799  15.02714348  13.57193375]\n",
      "\n",
      "Step : 3530  loss : 0.5361327528953552  \n",
      "real : [ 13.18134758  17.08873033  16.53804228]   \n",
      "pred : [ 14.00647354  17.29196548  17.15104866]\n",
      "\n",
      "Step : 3555  loss : 0.2694893181324005  \n",
      "real : [ 13.71005311  12.91473058  13.10542019]   \n",
      "pred : [ 13.38354874  12.56989956  12.55881882]\n",
      "\n",
      "Step : 3580  loss : 0.3083724081516266  \n",
      "real : [ 16.26913269  14.27015025  18.61613797]   \n",
      "pred : [ 16.34685707  13.38578129  16.8123436 ]\n",
      "\n",
      "Step : 3605  loss : 0.41500231623649597  \n",
      "real : [ 12.5481356   15.62763868  15.39949069]   \n",
      "pred : [ 12.58479118  14.76943588  15.02850151]\n",
      "\n",
      "Step : 3630  loss : 0.30647000670433044  \n",
      "real : [ 19.12700887  12.94059106  16.99921259]   \n",
      "pred : [ 19.69442177  13.09445     15.46099949]\n",
      "\n",
      "Step : 3655  loss : 0.25543680787086487  \n",
      "real : [ 15.83560218  13.96387225  14.0263439 ]   \n",
      "pred : [ 15.84023666  13.6365881   14.98843479]\n",
      "\n",
      "Step : 3680  loss : 0.5992581844329834  \n",
      "real : [ 14.07330722  17.03308806  13.52989134]   \n",
      "pred : [ 13.27309132  16.13550949  12.87310886]\n",
      "\n",
      "Step : 3705  loss : 0.4706951975822449  \n",
      "real : [ 13.17235219  13.05823798  13.44327357]   \n",
      "pred : [ 14.43650436  13.76856518  14.21590996]\n",
      "\n",
      "Step : 3730  loss : 0.7844710350036621  \n",
      "real : [ 16.57095726  13.47642816  18.69010792]   \n",
      "pred : [ 16.37879181  13.55769825  18.92548752]\n",
      "\n",
      "Step : 3755  loss : 0.4498606026172638  \n",
      "real : [ 14.12442555  14.81865874  19.4570242 ]   \n",
      "pred : [ 15.08664799  14.97806931  19.53557014]\n",
      "\n",
      "Step : 3780  loss : 0.3978857398033142  \n",
      "real : [ 13.66917231  11.7841245   15.11721515]   \n",
      "pred : [ 13.7456274   11.94536495  14.86353493]\n",
      "\n",
      "Step : 3805  loss : 0.31132328510284424  \n",
      "real : [ 12.52156494  17.18242046  16.29120225]   \n",
      "pred : [ 13.27908421  16.9644146   16.1635952 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Training\")\n",
    "train_writer = tf.summary.FileWriter('logs/train',\n",
    "                                    sess.graph)\n",
    "step = 305\n",
    "n_iterations = 15000 - step\n",
    "for i,(x_,y_) in enumerate(gen_data(batch_size,num_steps,\n",
    "                                    train_data,shuffle=True,n_iterations=n_iterations)):\n",
    "    #print(x_[0])\n",
    "    if(y_.shape[0] == 0):\n",
    "        continue\n",
    "\n",
    "    _,loss_,pred,summary = sess.run([train_step,loss,logits,merged],\n",
    "                                    feed_dict = {x : x_, y: y_, keep_prob : 0.8})\n",
    "\n",
    "    if tensorboard:\n",
    "        train_writer.add_summary(summary, step)\n",
    "\n",
    "    if(i % 25 == 0):\n",
    "        print(\"Step : {}  loss : {}  \\nreal : {}   \\npred : {}\\n\".format(step, loss_,\n",
    "                                                                                       y_[0:3],pred[0:3]))\n",
    "        if save:\n",
    "            save_path = saver.save(sess, checkpoint_path)\n",
    "    step+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halifax Energy Balance 5min 2013\n",
      "Halifax Water Balance 5min 2013\n",
      "Halifax Lysimeters kg 5min2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/Recurrent/load_data.py:77: FutureWarning: how in .resample() is deprecated\n",
      "the new syntax is .resample(...)..apply(<func>)\n",
      "  'Wind': \"mean\",'Rain': \"sum\",'Lysimeter': \"mean\"})\n"
     ]
    }
   ],
   "source": [
    "test_data = load_data([\"Halifax\"],['2013'],resample=resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration : 0  \n",
      "real : [ 12.85538989]   \n",
      "pred : [ 15.81344604]\n",
      "\n",
      "Iteration : 50  \n",
      "real : [ 14.32238941]   \n",
      "pred : [ 15.31957245]\n",
      "\n",
      "Iteration : 100  \n",
      "real : [ 14.12641314]   \n",
      "pred : [ 15.10767651]\n",
      "\n",
      "Iteration : 150  \n",
      "real : [ 13.68454541]   \n",
      "pred : [ 14.79423237]\n",
      "\n",
      "Iteration : 200  \n",
      "real : [ 16.19634302]   \n",
      "pred : [ 16.43298531]\n",
      "\n",
      "Iteration : 250  \n",
      "real : [ 16.00943825]   \n",
      "pred : [ 16.41513062]\n",
      "\n",
      "Iteration : 300  \n",
      "real : [ 15.64732953]   \n",
      "pred : [ 16.76312065]\n",
      "\n",
      "Iteration : 350  \n",
      "real : [ 16.55441535]   \n",
      "pred : [ 17.14958763]\n",
      "\n",
      "Iteration : 400  \n",
      "real : [ 15.76908648]   \n",
      "pred : [ 16.2614727]\n",
      "\n",
      "Iteration : 450  \n",
      "real : [ 16.69262015]   \n",
      "pred : [ 14.2934885]\n",
      "\n",
      "Iteration : 500  \n",
      "real : [ 16.13483198]   \n",
      "pred : [ 16.38731384]\n",
      "\n",
      "Iteration : 550  \n",
      "real : [ 16.33598256]   \n",
      "pred : [ 16.71316338]\n",
      "\n",
      "Iteration : 600  \n",
      "real : [ 15.96686627]   \n",
      "pred : [ 17.05530548]\n",
      "\n",
      "Iteration : 650  \n",
      "real : [ 15.94554843]   \n",
      "pred : [ 15.7960577]\n",
      "\n",
      "Iteration : 700  \n",
      "real : [ 15.58133918]   \n",
      "pred : [ 16.09435654]\n",
      "\n",
      "Iteration : 750  \n",
      "real : [ 16.4987683]   \n",
      "pred : [ 16.64162064]\n",
      "\n",
      "Iteration : 800  \n",
      "real : [ 16.64506205]   \n",
      "pred : [ 15.85938263]\n",
      "\n",
      "Iteration : 850  \n",
      "real : [ 16.81677426]   \n",
      "pred : [ 15.93118668]\n",
      "\n",
      "Iteration : 900  \n",
      "real : [ 16.90356847]   \n",
      "pred : [ 16.54907799]\n",
      "\n",
      "Iteration : 950  \n",
      "real : [ 16.83202764]   \n",
      "pred : [ 17.64133072]\n",
      "\n",
      "Iteration : 1000  \n",
      "real : [ 16.81499125]   \n",
      "pred : [ 18.63706398]\n",
      "\n",
      "Iteration : 1050  \n",
      "real : [ 16.87384263]   \n",
      "pred : [ 18.54398918]\n",
      "\n",
      "Iteration : 1100  \n",
      "real : [ 17.12858326]   \n",
      "pred : [ 19.32781601]\n",
      "\n",
      "Iteration : 1150  \n",
      "real : [ 16.68333896]   \n",
      "pred : [ 18.7349987]\n",
      "\n",
      "Iteration : 1200  \n",
      "real : [ 16.72635003]   \n",
      "pred : [ 18.01442719]\n",
      "\n",
      "Iteration : 1250  \n",
      "real : [ 17.09607098]   \n",
      "pred : [ 17.49210167]\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "pred_data = test_data[0][['Lysimeter']]\n",
    "pred_data.Lysimeter.iloc[0:num_steps] = 0\n",
    "for i,(x_,y_) in enumerate(gen_data(1,num_steps,test_data)):\n",
    "    if(x_.shape[0] == 0):\n",
    "        continue\n",
    "    #print(y_)\n",
    "    \n",
    "    pred = sess.run([logits], feed_dict = {x : x_ ,  keep_prob : 1})\n",
    "    pred_data.Lysimeter.iloc[i+num_steps-1] = pred[0]\n",
    "    #print(pred_data.iloc[i+num_steps-1])\n",
    "    #if i > 5:\n",
    "    #    break\n",
    "    if i % 50 == 0:\n",
    "        print(\"Iteration : {}  \\nreal : {}   \\npred : {}\\n\".format(i, y_[0:3],pred[0][0:3]))\n",
    "    \n",
    "   # if i >= 300:\n",
    "    #    break\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_rename = pred_data.rename(index=str, columns={\"Lysimeter\" : \"Predicted Weight\"})\n",
    "real_rename = test_data[0][['Lysimeter']].rename(index=str, columns={\"Lysimeter\" : \"Real Lysimeter\"})\n",
    "\n",
    "result = pd.concat([real_rename, pred_rename] , axis=1)\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAE8CAYAAAAxL51GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzsnXd8VUX2wL/npfceCBASaug1gkhH\nBMSKXSzg6upv7ZW17aor9u7qqtjQtYuLikqTIiK9F+kQIIGE9N4zvz/mJnkJLwkJLySB+X4+7/Pu\nm5k7M7e8e+6cc+aMKKUwGAwGg6E2bE3dAYPBYDA0f4ywMBgMBkOdGGFhMBgMhjoxwsJgMBgMdWKE\nhcFgMBjqxAgLg8FgMNTJGS0sRGSqiCy3+50jIh2tbS8RmSMimSLybdP1smUiIk+KyGenqK2OIpJz\nKtoyHI+I3CIiS5u6bRFxsf7D7U9Bu8tFZGpjt9OcaNHCQkTiRGRstbQqAqA+KKV8lVL7rZ9XAK2A\nEKXUlSfZVfv+eYjIhyJyUESyRWSTiJxfrcy5IrJTRPJEZImIRNnlXSUiK6y8pdX2CxWRP0QkVUQy\nRGSliAytpS8zRaTI+oOlichCEenmrGOtpd1RIhLvrPqUUvuVUr7Oqs8eEflMRJ5shDqLrOufLSJb\nReQZEfGvRx3xIjLKmf1qDESks4go6x7LEZEDIvJQY7SllCq1/sOHTqRPjdEHq/7pIlJsd313icib\nItK6HnU0O2HUooVFIxMF7FZKlTi5XlfgMDASCAAeB74RkWjQD3zgf8A/gGBgHfC13f5pwOvA8w7q\nzgH+AoQBQcALwBwRca2lPy9aD9q2QALwYQOPy+CAWs79s0opP/S1uhkYDvwuIl6nrHOnEOsh7gvc\nAPyr+kse1HquWiKfW9c3BLgciATWiUirpu1WwznthYWIPCwi+ywJ/6eITKqlrLLeOp4C/glcbb0N\n3SwinURksfXWniIin4tIoLVfJ+vNfID1u42IJDt681NK5SqlnlRKxSmlypRSPwEHgIFWkcuA7Uqp\nb5VSBcCTQN/yN36l1K9KqW+AIw7qLlBK7VJKlQEClKKFRnBd50kplQ98A/Srdk7+IiI7RCRdROZX\nG+W8ISKHRSRLRNaLyPC62qkNERkiIkdExGaXdpWIrLe2zxaRDVZ7SSLykpVe5U3Reiv7l4isEpFc\nEfleREJE5Etr39X2qgoR6SEiv1rXcKeIXG6l3w5cDTxq3QezrfR2IjLbusYHROQOu7qmi8jXVlvZ\nwPW1HbN1zdYAFwGtgSlWPV1EjyrTrPvtvyISYOV9CbQB5lr9ul9EbCIyS0QSRY8ql4pI91rO9S3W\ndc22/h+32OWNFT1qn2Yd4xERudEuP0xEfrLO5SqgQ23HWO14lwM7gV4i4mr9524Xkb1Weo3Xo662\n7eqLtn57i8hrInJItDp5mYh4AMus/PLRzll252Snda/PFZFIu7oniB4hZIrIG+j/14kcb5FSahtw\nJZAB3GfVFyIiv1jnN120yrutlfcCMAR41+rf61b6W6JHlFkislZEzjnR8+4UlFIt9gPEAWOrpU0F\nltv9vhL9x7Kh//i5QEQNZRXQ2dp+EvjMLq8zcB7ggX4bXAa8bpf/V+BPwBuYD7x8gsfQCigAulm/\n3wDeqVZmG3B5tbRbgKU11LkFKLKO5/1a2p4JTLe2fYD/Apvt8i8B9gLd0SOix4EVdvnXo9+cXIEH\ngETA09H5q9buKCC+hrxdwHl2v+cA91jba4FrrW0/YLDdtVF2+yy36umIFpY7rd+jrb5+UX5eAF/0\niOpGK28gkArEWPmfAU/a1W0DNgGPAu5W23HAuVb+dOvcX2SV9XJwjFXqtEv/Av1GCtAVONdqIxz4\nw/6eAuKBUdX6NdU6L57AW8C6Wq79Rdb5EWAMkA/0sfLGAiXAE4AbcDH6f+Nv5c8CvkTf632Ao9R8\nL1ZcG6ut4ej7faR1vhUwz7pOXidwPWps266+aOv3e8AiIAJwAYZZx1PlfrHKXm7dIzFWPU8Cv1t5\n4ehR+yRr/4es8zO1hmOeDsx0kP4s8Ie1HWbV5wX4o7UJs6rdw1Or7X8D+sXPFfi7dZ48TuQ544zP\nKWmk0Tqv/6Q5aIld/snDTgA42GcTcIm1PZUTFBYO6rkU2Fgt7UdgK/phXedFtG68X4H37NI+BJ6v\nVu4PBzdOjcLCyvcErgWm1FJmpvXHzQDK0COcPnb5c4Gb7X7brPMbVUN96UDfus4ftQuLx4BPrO1Q\nq71w6/cK9IgvpNo+joTF3+1+vwHMsfs9CetBClwHLKlW34fAY9Z2dWExFNhfrfw/qBQ+04HFdVz3\nmoTFy8DcGva5Alhr97uKsHBQPtS6n31O8L/0E3CHtT0W/b9ysctPA2Kte7ak/H9i5b1Y071Yfm2s\neywd2GHXTvnDfYRd+RqvR11t29UXjRYOhUDPmvpULW0hdv8Vq65CtHr2L1R9TtjQQmpqDcdck7C4\nE9hRwz6xQHK1e9hh/Va+ANmOjq+xPqeDGupSpVRg+Qe43T5TRG4UbUTOEJEMoBf6j1QvRKSViHwl\nIgkikoX+w1ev532r/n8rpQrrqM+GfpMvQt9E5eSg3zTs8UffGCeM0uqNL4GHRaRvLUVfts5bNPrt\nMsYuLwp4w+7cpaFv0vLh8oOWKiPTyg+gAee2Gv8FLhGtu78G/eA4ZuXdBPQAdonIGhGZWEs9SXbb\n+Q5+lxvEo4Ch5cdoHcfV6LdRR0QB7auVn4ZWIZVzuO7DdEhb9DlGRFqLyDd299tMajm3oj2BXhSR\n/Vb5vVaWw31E5ELR6rg06xjGVSubopQqtfudhz5nrdAPYvtjPFjXgVn/zyClVHel1NvVsu3rqu16\n1KftVuhR2b66+mbX7tt2baagX6DaoTUTFW0qreZtiIOG/fX1FZEPLBVZFrCYOv47llpwp4hkogWv\nT137OJPTQVjUiGj9+vvoh3GI9VDcxgnqG6vxLPqtpbdSyh+tgqmoR0R80YbnD4EnRaRGO4GIiFWu\nFVq9VGyXvR3oa1fWB+hkpTcEN7S6oVaU9iC5By0cyo2sh4Hb7IWxUspLKbVCtH1iGnAVEGSd20wa\ndm6r92M9euR2A1p4lOftUkpdg1YLvAJ8JyKeJ9Me+hgXVTtGX6VUuQBXDsrvqVbeTyl1kf1h1LcT\noj2hxgC/W0kvoN9sy++3qVQ9t9XbuBGYaNURgH57BgfXw7q+s4DngFbWtVvgqKwDktAP0Ui7tJN1\nVbU/ltquR33aTkK/iHWqoz37dm92cK+vRo8i7O0XNrQQOWFExAWt+iu/vg+h7S2DrOs7prY+isho\n4H60uiwQrbbL4ST/b/XhtBYWaMmrgGQAEbkJ/ebfEPzQFyfTMkRVd/97A63auAX4GXi3lrreQdsB\nLlLasGzPbLTx73LrQfhPYItSqtz452KluwI2EfEUETcr72wRGSYi7qLnifwdLZBWn8gBKqUWog3n\nt1pJ7wKPiEhPq/4AESl3I/ZDqwSSAVcR+SfHj4hqxeq7/af8xv8UeAToBvxgV/4GEQm13uwy0de2\nrD5tOuBHoKeITBYRN+szSETKR1hJVBW2K4EiEXnA6rOLiPQWkYHH1XwCiHaljkUfZzL62EGf31z0\n/RYJPFht1+r98kMLl1S0Pv+ZWpr1QL91JwOlInIh2j5SJ9aLzffAU9Y91gst1J1FjdejPm1bo6KZ\nwOvWKM1FRIZa/5VjgBJrTpXFu8BjYjkFiEigiFxh5f0E9BORS6z970PbHOrE6n8P4Cu0veF1K8sP\nPVpLF5EQ9P/cHkfXtwQ94nFDq3l9TqQPzuK0FhZKqT/Rb6Ar0Se/N1r/3xCeAgagH1I/ow1SAIjI\nJcAE4G9W0v3AABG5rnol1mjnNrTXUaJUemRcZ/U5Gf328Ax6qDkYrY4p5wa0GuUdtLEwHz16Av0Q\neBv9wEhAv2leoJQ6znOqFl4CpomIh1JqNvoN9ytrqLwNKJ8TMh9tmNyNVgUUUD/1S1ur7/af8rfA\n79B/lFnVhOlEYIdoL6OXgauVUkX1aPM4lFKZwHj0SPEo2kj/HPpcAnyA9kZLF5FZSrtSTwQGoW1m\nKWhDar0EJdrDKht9rT4BVgFDlVJ5Vv4TVhuZ6Afod9X2fxb90MwQkXuBj9GC/gh6FLqilmMu98qZ\njVaLXIF+IJ4of0O/2SahR8gf12PfWjmB61Gftu9D20jWo4/zWUCUUtlWnaut8xerlPoWeBX41rrX\nt1j9QCmVhFaFvYS+3u2p+wXsOuv6pqNfBJKAWKVUopX/KnoEmIq+VnOr7f86cK3Vv1eBX9D2zT3o\n+y7LOj+nDLGMJQZDs8EaYRxAG/iWNnF3DAYDp/nIwtBiuQqtUvmtqTtiMBg0p9OMScNpgOhQLV2A\n65QZ9hoMzQajhjIYDAZDnRg1lMFgMBjqxAgLg8FgMNRJs7dZhIaGqujo6KbuhsFgMLQo1q9fn6KU\nOqH5ICdCvYWFNUHoU/RkLwXMUEq9Yc1Y/hodNiIOuEople5g/ynogHSgg9h9Ult70dHRrFu3rr7d\nNBgMhjMaEakzDEt9aIgaqgR4QCnVAzgbuMOaofgwepp+F3Skx4er72gJlCfQE80GAU+ISFBDO28w\nGAyGU0O9hYVS6qhSaoO1nY2eIdkWHc66fJTwCTq2T3XGAwuVUmnWqGMheuazwWAwGJoxJ2XgFr3I\nSH/01PdWSqny6eeJaDVVddpSNSREvJVmMBgMhmZMg4WFFWX1O+BepVSWfZ41marBEzhE5FYRWSci\n65KTkxtajcFgMBicRIOEhRV58Tv0ql7lAfWSRCTCyo9AR3asTgJVwwu3s9KqoJSaoZSKVUrFhoU5\nzZhvMBgMhgZSb2FhtxbDDqXUq3ZZP2KtH2x9/1B9X3Sk0nEiEmQZtsdZaQaDwWBoxjRkZDEUHSZ7\njOgV6DaJXrHseeA8EdmDXpbxeQARiRWRDwCUUmnA0+i1lNcC/7LSDAaDwdCMafaxoWJjY5WZZ2Ew\nGM4kDqfl8ewvO3jlqr54uzds7rSIrFdKxTqrTybch8FgOCM5llXAkYx8muML818/XcfcbYlsP5JV\nd+FTRLMP92EwGAzOZkt8BtfOWEVuUSk2gScu6smYbuHcNHMt5/Voxd8ndGvS/u1MzAbA09WlSfth\njxlZGAyGM4pv1h7m4rf+ILeolLvGdMbNxcYTP25n+ItL2Hssh3eW7mPg0wuZtT6+SfqXllu5UnBZ\nMxr1GGFhMBjOGMrKFNO+2wJAVIg3D4yLYcM/zmNCz9YA3De2KwCpuUU8+O1mMvOKT3kf/7RTPRlh\nYTAYDE4gLiWXOz7fwJGM/BMq//qiPRXbT1/SCwAfD1fevm4Av94/gnvGduHzWwbz0PgYAO74YsMp\nt2nsSsqu2G5OwsLYLAwGQ4vluw3x/Lz1KEE+bky/tHetZdccSOPNRXu4pF8bXr+6H3rKmMbFJnQO\n9wNgaOdQhnYOJTO/mBnL9rNyXyrndA5t1OOwZ3eivbA4Zc3WiRlZGAyGFsnauDT+vXgvACv2ptZZ\n/oV5O4kI8OT5y/pUERQ1cf95XQnwcuN/G48LMtGo7LQbWZQ2I2lhhIXBYGiRXPnuyort/Sm57LF7\nyFZnT1I26w+mc/OwDni5n5iHkaebC6Niwliy8xhlJ/HQLiguZdqszfyy9WidZcvKFHuSsuke4a9/\nNyM1lBEWBoOh2ZCYWcCaA1WDOpSUlvHY7K18/McBjmUXVKRHh3gDcPeYzrjahGnfbWHH0SzeWrzn\nODvDt+vjcbUJl/avX5DrMd3CSc0tYlN8RgOPCP678iDfrIvn9hOwrSRk5JNXVEr3CK0SKytrcLNO\nxwgLg8HQLDiSkc/ol5dy1XsrWb2/Uq205kAan68+xFNz/mTMy7+RmlMIQKivB2d3DOb+cTE8OD6G\njYcyOP+N33l5wW7e/31/xf4FxaX8b0M8Y7qFE+rrUa8+jewahotNWLzDUVzUuskrKuE/S/cSHeKN\nCHW64/55VHtCdW9tRhYGg+EMpS6vok9WxpFfXArAKwt3V6Qv+DMJD1cbz07qTU5hCV+vO0xRSRl/\nHs2ii2WUnjIkGpudGeLd3/ZXqI6+WnOIlJwippwTXe8+B3q7M7B9EL/tbthSCct2p5CeV8wzk3rT\nrbU/y/em1Fp+/rZE/D1d6d0uAIBSIywMBsOZxJdrDjHg6YVkFTiet1BQXMp36xMY0y2ca86KZMeR\nLB7+bgtLdh1jwfZERnQNY/Lg9gzpGMLnqw7x5qI95BWVMipGL2Hg5e7Ch1PPYnRMGPeN7UpabhF/\nHs0iPbeIt5bsZXCHYM7pFNKgvg/pFML2I5lk5td/zsWiHUn4eboyqEMwE3u1Zs2BNLYlZDosm1dU\nwrztiVzQJwIvN21XaU6hSIywMBgMjc4rC3aRnlfMmv2Og0z/svUoKTmF3DQ0mvYh3mQXlvDV2sPc\n9PFajmQWcJlla7hxSBQJGfm8tWQvF/dtw5hu4RV1jI4J5+ObBjF5cHsAftudzCsLd5GaW8TjF/Q4\nIQ8oRwzpFEKZ4jhbSvnIRSlFgTUiqs5vu5MZ2TUMNxcbNw6JxtPNVqMqau7WRPKKSrmkX1tsVl+b\nk83CzLMwNGuUUjw0aws2gecu64OLrWF/eEPTkl+kH6ZxqbnH5SmleP/3A3QM9WFY51ByC0sq8h4a\nH0O31n6c212v0nxej1ac36s1YX4e/H1CN4cCIMzPgwHtA3lp/i4ALu3XpkKt0xD6tw/Ew9XGyn2p\nnNdD9+PbdYf55w/bmXHjQI5mFjBt1haWPDiKDqE+Fful5xZxLLuQfpGBAAR4u9El3I8DKY7PwUd/\nHKBTmA+DooMrbBfNSQ1lhIWhWXMgJbfiTaxfZFDFW6Oh5ZCcXUiuJSwSMwuOy9+fksuOo1k8dXFP\nRIQB7YMQgcmD2nPH6M5Vyrq62Hjn+oF1tnn3uV2Y+vFarh0Uyb+smdoNxcPVhYFRQazYp+0NB1Nz\neWiWDhny4fIDJKRrD6ebZ64FgVev6ke/yED2p+QA0DGsUoC0CfRkf/LxwmJtXDrbj2Tx7KTe2GxS\n8VJk1FAGwwmyLi69Ynv2xqYJ7GY4Oex19IlZxwuLPyyj74iu2v4Q7u/JmkfH8s+LejS4zVEx4Sx5\ncBTTL+2Nm8vJP+aGdwljZ2I2h9Py+O/Kg9gERsWEsXRXMnuOaaGwPyWX/cm53PDhajLyith3TAuF\njqG+FfWE+HpUCRRYzg+bEvB2d2GSpW4rV0OVNiM1lBEWhmbNV2sP4WoTpp4TzabDGRXqDEMluYUl\nvDBvJ3uth1ZzY9PhDESgV1t/khwIi/nbE+kU5lNFhRPm54HHSYbn7hDq4zS15QW9IwDt+vrNusNc\n0KcNd9qNem4f1Yl3rx/Iu9cPILughJ+2HGX1gTTcXWy0C/KqKBfi4056XlGVSX6lZYr52xMZHRNe\nMWGwXL61aNdZEflIRI6JyDa7tK/tlliNE5FNNewbJyJbrXJm+TtDrRSXlrE1IZPJg9szMiaM4lLF\nhkPpde94hjFzRRzvLN3HtFmbm7orDllzII1ebQLoFObL2rh0nv1lB8nZeq5Eem4Rq/anMaFX6ybu\nZe20D/GmT7sA3li0h6yCEqYMiaJ3uwC6R/hz2YC2PDQ+hgm9WjO+Z2u6tvLl8e+38d2GeG4YEoWr\n3cgmyNudMgUZdp5V6+LSSMkp4vzeleeg3BbTooUFMBOYYJ+glLpaKdVPKdUP+A74Xy37j7bKOm25\nP8PpSVxKLsWligHtgzgrOhhXm7B0V8MmR51KlFIs2J7IjqOnZpWzXVbguU2HMziaeWLRV08lcam5\ndGnlS9dWek7EjGX7+c9SHdPphXk7KS1TTLTe3JszYy0je7/IQGKjg/FwdeGXu4fx6lWVQQlFhGcm\n9cbb3YV+kYEV0WvLCfF1ByAtt7Aibe62RDxcbYyOqfTscmmGwqLeBm6l1DIRiXaUJ/qMXQWMOblu\nGZojSVkF7ErMJq+olLHdw6u8MTUGGw/pEAvdIvzw9XBlTLdwvl57mIfGd8Pd9dRqUONScknIyGdo\nLdFHlVLc8cUGftmaCOgZxmsePRdbI3pwFZaU8uPmI7jahJIyxeyNCdw+qnPdO54iEjMLOJpZQKcw\nX/4ytAP9IwOZ/MFqPv4jjp+2HCU5u5BzOoXQs03DvZVOFTcP60BabhFXnxVZkebIG+us6GDWPDYW\nLzeX49RgYX56BvnRzAI6h/tRVqaYt03PI/GZew9s+gwufQfXkGHA6W2zGA4kKaX21JCvgAUisl5E\nbnVy24ZGoqikjBX7Urji3RXc+NEa/u+z9TzwbeOrPOZvT6RtoBcx1hvpVbGRZBWU8Me+2mfBOhul\nFNfMWMV1H6yuNbbPrqTsCkHh7e5CSk5hhQtkY1EehqJzuC89IvxZvufUnpu6GP3yUgCiQ3zwcnfh\nnM6h3DG6E6C9pDxcbbw9eUAT9vDE8fFw5cmLe1YE+XOIUpCbiq+Hq0N7SXkYj/IFjjbFZ5CYVcCF\n3QK0oAD4/m+0/bAPz7p+gH/GdqcfR0NxtrC4FviylvxhSqkBwPnAHSIywlEhEblVRNaJyLrk5IZN\nszc4j8e/38rk91dzOK3yQfnDpiMcSs0jLiW3Qe59Sim+XnuI6z9Yzbu/7TtOfZKUVcBvu5O5oE9E\nxdvb8K6huNqEdXGOJ3Y1FruSsiu8eLbEO559C/D9Rv2Gv+axc1n60ChEYOGfSY3atwRLeM24IZbB\nHYPZcCidopJT/zr63C87iH74Zw6l5lVJLw/fYT97+qHx3fjxzqF8+39D2PbUeIJ83E9pXxuVnx+A\nlzrCsZ0Os4N83GkX5MXauHQKS0p5as6feLu7MKa1dd5GPgxtYykJ6szlLr/jl73fYT1NgdOEhYi4\nApcBX9dURimVYH0fA2YDg2ooN0MpFauUig0LC3NWFw0NIKugmG/WVXVZvX2UfjO88r0VjHp5aYPW\nKv589SH+/t1Wlu9N4fm5O3l89rYq+Qu2J1JSprhyYLuKNA9XFyKDvYlLyateXaPyy5bK0NLL99b8\n8vL7nmQGRgUR7udJuJ8nwzqHMnNFHAcdTERzFik5Rbi72IgM9mJwhxAKistYd/DUCVOlFM/8/Cfv\nLdMPtVcW7qrIK3cRfWh8zHECoU+7QM6KDnaKW2uzoSAT1n2otz+/ErZ9p0ca1RjbvRW/7khi4hu/\ns/lwBn8d1gG/hD90Zsz58NdFuN69Fvd/JDDkwr+cwgOoHWdeqbHATqWUwyeHiPiIiF/5NjAO2Oao\nrKH5sP6g9j66bEBbVj1yLnufOZ9pE7pxYZ8IkrK0kW7utsR61zt7YwKdw3354Y6hdAn3ZduRyjf2\nktIyPlt1iI5hPnQO962yX4dQn1PuIrpo5zEGdwimX2Sgw9m3ACk5hWw/klUxVwDgqYt7UlBcyqt2\nQfGczaG0XNoEeiIijOgaipebywmtm+AMcgpLmP7zDt7//QAAEQGezNl8hHRLSKw5oCPHnt0x+MQq\nVArS9kPJ8fMQAMhPhyInvSjkp0PiVufUVU6ydZ0DoyDzEMz6C7w/Gn6ZBpu+gIQNkJ3I5b2D6C37\n6ZM6j+cDZnNP/L0w/xHwbQVh3QBtCxFXD3CtX5TcxqQhrrNfAiuBGBGJF5GbraxrqKaCEpE2IvKL\n9bMVsFxENgNrgJ+VUvMa3nXDqWDnUe1p8/gFPWgd4Flh1P73tf357m/nMKl/W1bvTz3hFb1KSsu4\n9dN1rD+YzqT+bekbGcj5vSM4ll1IsWXN+25DPLuSsrl+cNRxBsRBHYLZlZRd40Pb2eQXlbIzMZtB\nHYLpEOrDvmPHq91W7U8ldvqvABXhIAA6hvky5Zxo5mw+cpx6xhmUlik2Hcqgm6UH93Z3ZUz3cD5b\ndYgfNjlpdbfkXQ7fjgHu+3oTHy4/QICXGzufnsDzl/ehL3sqFiFatT8NTzcbfVwOQ9zyutv67UV4\nsz/Mfchx/gvR8N5wvZ2yB6a3hk8uhrwGjKQ+ngjvDoONn9d/35rIPqK/r/wYLn1Xq5RcPWHjZ/D9\n37TgeCWG3p90Z47H47zm/g7XFH6L7fBqOPcJuPU3cPN0Xn+cTEO8oa6tIX2qg7QjwERrez/Qt77t\nGZqW9QfT6BjmQ3A1NYKIMDAqiH3Hcpi9MYH49DyiQnxqqKWSL9ccYoGlx795WAcAwv08UApSc4rY\nHJ/B37/bSoCXGzcNjT5u//E9W/P83J2s3p9aZRJXY7E1IZPSMkW/yEBa+Xsye2MC249k0attpffO\ny1YMorvGdK5wDy3n5mEdmPlHHO/8to/nLqt9jej6snJfKkcyC3h4YqXb6b3ndmHjwXSe/mkHF/Zp\nc3KT0hK36gfq6Mdg5LTjssvtMVPOicbTzYWB26Yz22MmpZ9Nh3PuYsSfW7nV/U/cPrAE18CboPcV\nED3s+LbKSmHps3p7/UxoOxAG3FiZX2rNS0jdCyvfhqTtUJIPB36Dd4bCyIeg+8XgcwJrZeelwbE/\n9fbP90NoV4g86wRPSi1kW/apgPa6/wCjH9HHlroPUnZBzjEozAavQGg/BHJTwDccQrucfPuNjIkN\nZaiVXUnZ9IsMqjE/ylqt7GBqpbBQStUY4XNbgvYC+fims/C0wjAHersBkJlfzI+b9dvZrSM6Oqwj\nKtib1v6eLN55jGsGNX6cqN/3JNPdJZ7B6Ucp7DWZx7+HC/+9nAX3jaBLuC8zV8Sx7mA6D5/fjf8b\n2em4/Vv5e3LNoEg+X32Iu8Z0pk2gl4NWGkD6QVj0Ct4u53GuXeTVLq38eOyCHtzxxQY2HkonNrpS\nBZRfVEp2QTEhvh6VQmT7bAjvAWEx1VvQKiGg5PfXOXdFX16/ug/9fTMguBMFSl+7awe1555zu0BZ\nGb5bZgLgUlYMy1+t6j/v4Q9bvoH1H0NQtFa5dL8YgjtAq14wY5Qu16Y/eAXBj3fBwicgeqgul2M3\nv2b+o5Xbl/wHNnwCP92nPz5hENgeXNz1A7isDIpzwb8t2FzBMwCOWnOGL/8QFj8NX1wJwx+APlfr\nB3dDyT6q2/CuFgrd5gJhXfWnOo7OezPFCAtDjZSUlnE0o4CL+tT8gIsI0HmJWQUopZixbD+frjzI\nV7eeTWSw93Hl18alMaZbeJWlgozcAAAgAElEQVQJSAFeWlhkFRSz71gOo2PCjgsgV47NJpzVIZiN\nDZnJXZQHqXugVW+wHa+BTcst4vVfd/PQ+Bj8PHWfEg7uZa7bNFgAviXpPHvpVTz6/Tae+GE7ri7C\n73tS6BHh73AUVM51g6P4dOVBVuxL5Qo7g/3JoBY8xrDEOdzTujU+HhdVySu3EayNS8fb3ZVv1h3m\n/nFdGffqMhKzCjivkzdvTwzB3csPvp0K7n7w9zhwsXsclJXCN/rN3rUkl1+Lr8XtUyvUioc/B3vc\nTazYGNW+kxY8Odrwv8+lA/FeMYwcPobpc3dT0u8Gnrygm1avFOfDircgeadWby14rOpBdRwF136l\nt9d/okc2e+bDjjk6zbc13LcNDq6ALV9Dl3HQ81LoN1mruY5uhuQdkHVEt7X5a/AO1g/wvPlQVgKl\nlj2k24V6lNOmv7YtLHhcC6f2Z0PUUOg6XgsbzxOY/1GQqe+tfYssoXQaGe3tMMLCUCNJ2YWUlCna\nBR3/0C8n3F8b4JIyC3ht4W7eXKxn5r62cDevXt2van1ZBexPyeWVkO/hi1dg0jvgFUSQt3tF/oGU\nXK6OSILSAVUfXnZ0a+3HnM1HyCooxt96qNfJ76/Coqf0dpfxcMnb4FvV0+6BbzaxZFcyPSL8K0Yt\nLimV3j0sns7kSZGkj4+tCH89eXB7Hp3YvdY4Rl3CfQnwcmNdXJrThEVOQTF+wMWyXNsUSgph508Q\n3JGQiH50CPXhhXk7eWGeduH8ZGVchelh4MEPcX9/jn77BijK1gbW3ldCu7NABDIOAbC8tCefl47l\ncpdljHXZCG0GoFQpMRunM8sD1PyXYUs/yNXCYkmrm5iZ3pv5/Ubwwez5PBTgW6mHd/PS6iLQfc4+\nqh/s22frEcHQe3TbAGf/n/4uKdQjnOyjWr3j4gYdR+pPOSLQYbj+2KNUZX3lFOVqoeFuqQtDOsFt\nv2nhtfkr2L8Efn8Zlr2o8z0DdLuBkXpE1Lq3VqMFRFbWPe8R2GTZPi56o34XsgVhhIWhKgWZcHQL\ndBheMQGtTWDNRjdPNxeCfdzZm5zD4h3HaBfkRedwX5btST5OHbVqfyqDZQf9D36sE16IhsjBdIsc\nSjeXNvyytTXhpUe5acd98NxdcMtC/eesRg9rUtTOo9rwXIXvboE9C+CuDVX115u/0sbGwbfBH2/C\ny52h7UCKrvqKf69OJ9TXgyW79ANvpxU+o7i0DNfcI/pfcud6+N9f4denuHnk42zuEkm39q25b2yX\nOhfVsdmE2Kgg1jpxfkhexjH8gIiUP+D5KCi0m/8x4EbO7vhXDqTkICgUNpSCpy/pyfVnR7H2udeh\nSK+V4OIZAO0GwZoZ+tOqN7QbSGpOISHA6yWXs051w737RA4e+oSbL76DFVmhPPnxDzw10p9zCv+A\ntAN6xCY2bG36Eb8/h55PzAe0oHSICPi30Z92tUT+cfWA8O76U18cXRf3GuxcYTEw9gngCW3TOLAM\nMg5CxmHIPKzVfvuXQrHlqOAVBCGdtTpt5086LXq4VmWdphhhYajKzw/A1m/h3m0czdRvy3Xp2Xu2\n8eeHTdrW8O4NAzmclsfSXcnsS86t4vq6an8ak9xX6x+jH9NGxsNrcD38Ku96dWDU1ukMEOuhV5IP\ns26G21dqna8dfayFbK59fxXf3DaEgVF2NpWt3+rvtR/AqIe1OmXx09q42OcaOO9f0HMS7PkVlr1I\n6bvDGJYbxPPF1wJdaBfkVaHiOpyWx1hZR4F7CJ7BHeH8F+CLq/H86XZm9JwE5808sXNaWszFAfu4\nZ6evfgj7nrw7ZGleJsskluHjLkeStkHiFv226+EHGz7lqa5pPOf5EyWewewJHMaOmDu4bEg0AP3D\nYMPR3lyfdx8vje/OBYN76Df8fYu1wNj+PSEFOtRKQPterJo8kv+uiuO5HRcxJawH8Yfj2aPa0X7w\naAiy/F2yEyE3hR55EbB8FQCXD2hXsWhRi8I7WKu3qlNWqlVoccvh2A5I26cFZWhXGP2ovq9OY4yw\nMFQly/LR/+wy2vqORBhJ6wBPrQ/Oz4CIvtqTw44rBrbjdyvMRP/2gUQE6JHI0l3HqgiL1ftTuco7\nG/x7V/WuWfcx0T/dy8W2FZRgCYYhd8LKt+DNftBmAEx8qcL4WP6wLS1TXP7OCjb847zjvLX44w3w\nDNT7LH9Np3WwAga06a8/Ae1I+vVdzpLN/NvjbQ5dNoeFB0v5+I84vll3mFBfd7pKPLnthuFps0Hk\nIHhoH/z6BKx4U+vYu4zTb8e1seUbLtl8OyVuw9i7DkJGXuD4rbcelBQV4O3tiwy5vWpGYQ4U5+Me\nvxYA17IiuifPp3v+JvC4DUK74JZ3jD7dY+mW3JqHfzlMv5gOtA1sA/2vh/7Xk5tfwOvPPUSf9mF8\neMt4AKKCfSgpUxzJKCAlR+v9Q3zshJ5fa/BrzWCluGtMZ8Z2b0XfyKr3SYvH5gKteurPGcjpaYkx\nNJyDlj98zjEGxr3Pxe4b8MvcA++NgE8vhs+vOM7vfmLvCDzdbIT6euDt7kqHUB/aB3vz0vxdZOZp\nl8dye0WYpzp+olHvKyn1DOZN97f5j/ubOm3AFBj3jPbU+fN7/XC247YRHSu2v1xzqDLDxQNiLtB/\n6Hl/h1k3gc0Nph2A/tdVFDuclsf7WYO5zeVp3g59jHYc45z/DeZv++/EjRKmzdrC/mM5hEkGPiF2\ndgabTevW/dvBnHvg3wO1W2RtZOlR1+Uuyxm89DotBE9icllKTiG2skL8/RyoVDx84er/wgM74Z9p\n8GgC3DAbCrO0QfmLqyA9DteACN64pj+FpWW8tbhqKLeftyXzftEEIsbeWZHWvtzrLS2XtNwivN1d\nKtZesEdEeGBczOknKAxGWBgc4B0K0/aT6BbJ87a3kXeG6PSYCyB+LexdVKW4m4uNZdNG89tDowD9\nwBjaOZTCkjKmzlxDWZlijuUSG+RIWHj44nL7Coovn1mZFhQN59wJk7+GTmNgxb/h5RjYpOd9PjQ+\nhl3TJ3B2x2C+WnuoclJgWTG06gG3/Aq3LYOh9+o6vKvaNqZ+vIZnftnBrqRs6HEp3DQPzrmb8PQN\nPOf5Cbd4/Er84Tg8pRjPoGrhs31C4e4NMPVnrZr4/nZY837Nk8Oy4sE7hNvCPmeDaz/tefNsBPxw\n53FFS0rLuPvLjUx+fxUl1UKOFpaU8p+le/ls1UHcKSHI3++4/atQrr6LHqq9naYd0JO/Op8H/W8k\nMtibq2LbMWt9PMes2FdKKd79bR/dI/yrqPeiLbfouNQ80nKLjh/JGU57jLAwVMUzAHpdDjYXnvN7\nhD98xup0V0+44iPtGfL1dfDZFRV++GQcJrwsBR+PSq3mXWM60z7Ym42HMuj/9EKm/7yDs6KD8LGV\nOg5h4B+BW+9JcMca7f/uavcwmjQDxk3XRsXFT0NZGa4uNjxcXZgyJJrDafl8u+6wfnCrskovn4i+\ncN5T0PncKk0ppdhntw7yWR2CIWqItmd0GMEVLOJx+Yh7dk/RBXwd6N1dPbRXzMhpEL8GfnlQj7ri\n1+tJV/akH4TAKM7q04OpObeTOfwJLQA3/leP2Bb8Q6uPgM9WHeTHzUdYsS+VNQe08Cko1vMjluxM\n5sV5u3j91z14UExwXcLCHhEtMIffD9fPqvD5n3pONMWlinnbdciWBX8msT8ll5uHdahiuA/388DT\nzcaKvSmsjUsj1Al2F0PLwggLQ1WK88HNC6UUv2WEsajTI3DfdvjrEu0Cef0sPRP30CptDC/IhI8m\nwGs94ZspFXF92gR6Mf9ebSPItFYFu2xAOygt1KqimgiL0f7v9viGwTl3abfLrAR4rh3871YoK2N8\nz9Z0Cffl4f9t5cVftujyLrW70x6sFnqjX7nKRASu+YIjN/zBQ8W34kseJeKq7Rs1MeJBeCxRTw5L\n2AAfjIHX+1SGySgt0e6YQVH0iwwkC182tLtezyfoOxnERaulPruMslXv8d3yjRUeRFustasveesP\nRr20lMU7KyPY+rqW4uJ+8qEhOof70TnclwXbdd1zNh8hzM+jYi3ocmw2oW2gF3O3JRKfnn9czC7D\n6Y8RFoZKSq1JS27eJOcUkpFXrB8KAe20agf0w/z857Wn0b7F8Hx7rWZx8dC2hQ2fVFTn5e7CtdZ8\nhYv7tuGq2EgtTFwbqMLoMQkmvACdRutJWb+/jK0wk0cnarfK/y7Xczyw1S4sDqVVCospQ6IqZpID\n4OFHRMeezLGNYUDhe3x69ty6QzG4emh7yN0b9OirtAjeHqRdWj+5UJcJjKrQ+x9KzdP7THoHbl2i\nPcMS1mObN403cx/m5W67GOFzmAPJuZSVKXYlZZOaW8Q36+K5OjaSuOcm4lJWVLvQrQcD2wexMzGb\n0jLF73tSGNk1zGGYEPvV7KaeE+2Utg0tB+MN1UQUl5bR5bG5TJsQU+vKZodS8wjwdquY5dyolFhr\nSrh7M3uDjufTv30Nhsqzb4egKO1GmLxTq4q+vl7Pgj20EgbdBu0H89xlvavGRKprZFEbNpuerDXo\nr1p9s+QZWPo8oy96g0X3X8JVr2p/94wiqM28etASFksfHFURrsQeESHEx4OEjDJCW9djEl1wR/0J\n6aIFaeIWPeHMOwSGP0CYhwfe7i4cTM2jrEyxdPcxRnUNxzbiQRh2P8+8+SYPZkynw5qH+BRYFHcR\n2Qu6EUF7jqJDSEwe3B5KCrS6zb3myZL1ITrUh5ScQlbtTyUzv5jhXRzHV7r/vK5cPqAd0acgJpeh\n+WGERRNRvkDNi/N21SgsikrKGPHSEvpGBvLDHUMbv1PFlrBw82LptmQ6hfkwoH0NcaFsNuh+kf6U\nc8lb2qawbzHsWQjXzdJ2AzdPPXPW3Ufr5t1OMj6SzQX+Mg8Or4Zlr8CPd9KJO5kf3gOyYE9KIbWF\nhfvzSCaB3m5EhXjXOKFuYFQQCRn5dG9dD7tAORF99AfgwtcAAU9/BGgf7M2htFyufX8Vqw+k8cyk\nXlw3OIoN8Zm8n9iF6AmLuC4Gtn96P+fmzIFVc5jr4cPPpWezrqwrvdtMgBzLvbl6DKIG0iFUC52P\n/4hDhBqXjhURIyjOYIywaEbsTspmT1IOo2LC8HJzoevjcwHYfDjj1HTAmp2ajwfrDqZx87COdexQ\njbAYuPozPQP8g7Hw0TitEoocrEcbZ/8N8lJ0iIWTxcMPOo/V0T3XfQRpBwjd+F8AlieUEZaSy4I/\nE5k8OApfj6q3+baELHq1Cah15vX0Sb24qG8burRqgLCwp1psoY5hPhVLr4K2EVw3OIoPlx/Az9OV\nS4f0BA9Xvu32BlM27OeJs0rovOafXOG1juuKF8H09/SoApwoLLT94dcdSQzqEGyM1waHGGHRRNjP\nVCiPcTT5/dWk5OgFhaYMiapS/n8b4knNKWLq0OjGW13MGlksO5BLcWkwo2IauEphRB+4e6P2Etq9\nAI5sAFWqDbkAoU6MtOkVpCOGKgVFORTsXMBXR1vzhrX2c5miSjTY3MISdiZm1SkI/T3dqqxN4SzO\n7xVRISwm9GzNvO2JfLH6EHO3HuWvIzpWeJQF+XiQUujC8oJo/un6KhsfPU/baRK3aiN/4jYd4toJ\ndAzzoV2QFyk5hdx7bvMPlW1oGoywaAb8a86f3HNulwpBAfDJyoO42oSZNw3i+g9Xc/83mwFIyS3k\nkfNrjpNzICWXwpLSigVx6oU1svhqUwqB3h2rhtGoLwFtIWBSZQiErCPw0Xj9cI9yzkOuCiJw5Uw8\nykp5YU8qd3+5kayCkoqV/spZsS+V4lLFiK4nsO5BI3Bej1aM79mKcT1aM7ZHK5btSebR2VtpF+TF\nX4dXCjAfD210X3swTY9uRKDvNfrjZNxcbPx45zAKS0oroggbDNVpyEp5H4nIMRHZZpf2pIgkiMgm\n6zOxhn0niMguEdkrIg+fTMdPJ2atj2f4i0sAeOXKvkzs3RrQb8RDOoXgZ6dG+Xh5XMWyldVJzy1i\n9MtLmfD67xVBAOtDXq6eH1CAO1/derZzRzD+beDerXqi3ImEfW4gYnNhVEw4G/5xHhN6tmZfctUl\nWHcc1etp1GiLaWQ83Vx474ZYLh/YjgAvtwoPo6cv7VVF/ePtrq/5/uTckxPaJ0iwj7sRFIZaacjT\nYCYwwUH6a0qpftbnl+qZIuICvA2cD/QArhWRHg1o/7SgfGnOy6r5s4+MCePlK/vy+AXduWV4B1xs\nwt12qoGi0jI21LCWw09bjlRsT3zz93r36fuVOwC4bVy/ho1MmhGuLjY6hftwMDWPguLSivQDKbm0\nDfSq6i7bhDw2sTuvX92PUV2rqvzKRxYAI7o0UB1oMDiRegsLpdQyoCGxlgcBe5VS+5VSRcBXwCUN\nqOe0okcbf/5z3QCevqQnB56bWBFf6ZbhHQm01nn4i7X8aDkJNYwaVh1Io7W/J53CfMjIK+bh77YQ\n/fDPLNudXGP7eUUlKKVIyMhny249T+Gc3t2cdHRNy9BOoZSWKeZvrzQo707KpmNY8/HoCfJx59L+\nbY8ztof7VU64G1w9DLvB0AQ401J6p4hssdRUjsbNbYHDdr/jrbQznom9I7hhSHSN3jkuNsHNRbiw\nTwTuLjYS0h0Li/3JufRo48/0S/W8hq/W6tN940drqrxdAyRnF/Lqgl30+Od8OjzyC0OfX0yEpKIQ\n3P1PYmnJZsTZHUNoF+TFN+v0ecjML2bH0azKGdvNmH6RgQzpGMKrV/XFdjLraBsMTsJZBu53gKfR\nTj5PA68Af2loZSJyK3ArQPv2jb/OclOg6i5SSXYSe64rhh4DGPXSEuJrGFkcycgnNiqIAVGB+Li7\nkFtUSrsgL+LT8+n2j3lc3LcNuxKzOZKZT2FJWcVcj3KGB6ah3DshbicfRqI5YLMJVw6M5PVFu9mf\nnMNvu5MpUzCia/NX63i5u/DlrWc3dTcMhgqcIiyUUhVBa0TkfeAnB8USgEi73+2sNEf1zQBmAMTG\nxtbruXpasvw1WP0ODLyJc717sD79+Hj6OYUlZOYX0ybQCw9XF7b/S5uVCopL6faPeQD8uPlIlX3G\n9WjFIxO7k1NQgr+XK1HzPoGc0yvmz8TerXnt191sjs9gzYE02gd7c1a0UesYDPXFKcJCRCKUUta0\nUiYB2xwUWwt0EZEOaCFxDTDZGe2f9pSvRb3+Yx5DuNblFaDqjO5DVnC8dkFVPVo83Vy4oE8Ey3Yn\noxT8/fxuLN15DC93F96aPKBqO6WFjiPCtmDah3gjooMH7krKpltDZmQbDIb6CwsR+RIYBYSKSDzw\nBDBKRPqhtStxwG1W2TbAB0qpiUqpEhG5E5gPuAAfKaW2O+UoWiCqPuOl0hLw8Ic7VlPyxkD+r+gT\nCo8MxiOiZ8WKa+stD6kYBw/Dty2hUL4m9g1nRx1XBtBB/lxOr3UKPFxdaBPgxe6kbOJScrmgd0Td\nOxkMhuOot7BQSl3rIPnDGsoeASba/f4FOM6t1lADSmlhUJyn4yn5t2FP55sYvettmDGUwhGPELOg\nN+N6tMLX05UwP4+K8NaOqC28BaBHFm7N3/hbX6JCvFm88xhlCrqebPgOg+EMxYQob2JqfYB/NEGv\n21CYVRF8L3vwA5xf+Bw7fAZT+Nvr+JDPgj+T+N+GBNoH1xwY74QoKTrt1FCghUVBsTbmOxp5GQyG\nujHCojlzeJWOB7R9NrjrEUPbQC92qCgeTZuIv+Sz0uMuXnd7C3eKHa5BUC9Ki+pcOKglUr4kaPVt\ng8Fw4hhh0VRYNouQrB3wzY2QneSgkIBPmF4c54JXAGgdoN1aN6ou3Fz0AJt9hnKpywp+cn+Up0te\nh5S9De/Tyaw10Yy5sG8bQK/N4e5qbnmDoSGYQIL1pbQEcpJg91y9dOb4ZyHjEAR10Gs81JOOSfPg\n4A86mui4Z/Rqc637wJA7AAWxN+t1ni3s4zW9/dRjOmzF+k+I2vQt7gmLYE42TP25wvB9wpSVQs4x\np4W9bk60DfTi92mjCfc//QShwXCqMMKiOkV5cGQjRFdbbOjIJv0Afm9E1fQ1M/T3Ba/CWTfXuzmv\nolS9kbYfvrJ8B7Z8DWfdorcdLEH64hV98Pd0q4xvNHAKHgOnwMr/wPxH4OlQiDkfrvxUC7CyUhBb\n7QIkeac2pNe23nQLJjLYOavKGQxnKmZMXp2502DmRC0w7JkxsqqgGHRb1fw9C6GkUH9OAGXpoVxL\nCyCsG8RWm/B+dJP+th0vz6+KjWRCr9bHVzr4Nrj43zos+I45sPhfsOZ9eLYtvNkPNn5ec4c+tcJ0\ntR1QcxmDwXDGYkYWoF1Us4+CqydYq62Rug/y0+HnB+A2uwiukWfDjd9r7ySbKwR3gNS9sPpdmB4O\nfSfDpHdOuGm30nzw8NLLb17wKmz8DH68U6/9AFo9daLYXGDAjdDveshO1DO/Adz9wCsYfrgDDq6A\noGit5ipfw1kpyLWCDQY7YRU7g8Fw2mGEBWg7wbdTq6ZlH4Ulz2j10LuWSqr3lXD5B5VlJjyrv/Mz\ndPk/f4DNX2iVT2kRXPqfOr2LXMoKwM16aItASLX1uNsNqv/x2Gxw449aiCVugfDuWkDMuhl2/ayF\n4IHf9EQ/ESjI1PuNfapBdheDwXD6Y4QFQNKfldu9r4SdP0PWUb3OM0B6nP72rGHCmlcgXPUpbP4K\nZt8Gmz7T6X2uhkMrdJ3hVVe3K5/B7VpaAG52sYrsy923HfzaNOyYbDYI66o/5Uz+Sn8veQ5+e16P\nOIqywTsUfFtBx5ENa8tgMJz2GGFxbCfstIt7eMErkLBBr3OccVjPbxj5dwjuCFHn1F5Xl3HQdiC0\nGQBr34cf74LsI3B0C1w/y+EuXkWp4Gm3foRXIJz/IrSLhYB2TjhAB4x+RKuhPPwqjd7ls8UNBoPB\nAUZYfHw+5FtrOcVM1Et+pu3TH4BJM6Dv1SdWl3cw/HWx3t4+WwsK0K61Dugmh/AtSISIvlUzBt/m\nsLxT8ay2Ep4RFAaDoRaMgrqkoHL7yk/0d8wF+nvAFO1Z1BAG/1/ldubhSr3T+pna8yj7KKFi2Qra\nndWwNgwGg+EUYUYWHn56fgFUzmm46lNtoHY/Cd/8kQ9B/+u0HWPRU/D7K7D46Yps7+XP4lm+UKCb\nVw2VGAwGQ/PAjCwcheR2cT05QVGOfxsI7aK37QQFvq2xZRzEkyL929UIC4PB0LwxwsLBpDenEhB5\nfFqH4diyE/AUS1icJsuYGgyG0xejhmrsKKuBdmuIRw/XNpCMQ9hyEmmNZVg3IwuDwdDMachKeR8B\nFwLHlFK9rLSXgIuAImAfcJNSKsPBvnFANlAKlCilYhvedSdRPneiVe/Gqd8rSE/Sc/GAKXO019Ha\nD5HSIh50+5YiV1/cvU6/BYcMBsPpRUPUUDOBCdXSFgK9lFJ9gN3AI7XsP1op1a9ZCAqAggwdCuOa\nzxqnfhG4bRncvqLSPdVulvbq7o+elgsOGQyG04t6Cwul1DIo159UpC1QSpVYP1cBjTSbrBFIPwj9\nr9fhMBqL1r31pL5y7ITFwYjqctdgMBiaH41h4P4LMLeGPAUsEJH1InJrI7RdP4oL9II/ngGntt2A\ntmSPf41BBW+jxOXUtm0wGAwNwKnCQkQeA0qAmmJhD1NKDQDOB+4QkRGOConIrSKyTkTWJScnO7OL\nVSnM0t+nWlgABb2u4xhBp7xdg8FgaAhOExYiMhVt+L5OqfLpylVRSiVY38eA2YDDkKpKqRlKqVil\nVGxYWJizung85dFWawoQeCowYTYMBkMLwCnCQkQmANOAi5VSeTWU8RERv/JtYBywzRntN5gKYeFf\nezmDwWA4w6m3sBCRL4GVQIyIxIvIzcBbgB+wUEQ2ici7Vtk2IvKLtWsrYLmIbAbWAD8rpeY55Sga\nSoHl3dsEaqjylfIMBoOhJVDveRZKqWsdJH9YQ9kjwERrez/Q11G5U86uuTD/Ub2wEYBPI6q66sAo\noQwGQ0vgzJvBXVoCX15T+XvQbRBilhI1GAyG2jjzhEX5GtsAk7+FruOaph9GC2UwGFoQZ56wOLQS\n/CLg/h3NwhOpGXTBYDAY6uTMizqbm6KFhXlKGwwGwwlzBgqL5CY1aJdjtFAGg6ElceYJi7xU8Alt\n6l5UIMYfymAwtADOLGGhlDWyaD7CwmAwGFoCZ5awKMzWa2t7N72wcBwQxWAwGJonZ5awyLWCEjaj\nkYWxsxsMhpbA6Sssju2A+Y9Bfkbla3xeqv5uBgZug8FgaEmcvsJizwJY+Ra8EAVv9oPifO02C+Ad\n0rR9w8SGMhgMLYvTd1LeOXeDq6eOA7V/CWz+Cg6u0HnNaGRhtFAGg6ElcPoKCxEYfBsMmALPtIKf\n7q3MC2g5q74aDAZDc+D0FRbluHnCqEfgwDJo1Qta92oWVmXjDWUwGFoSp7+wABj1sP40Q5qB3DIY\nDIY6OX0N3AaDwWBwGkZYNBFGC2UwGFoSDVlW9SMROSYi2+zSgkVkoYjssb6Dath3ilVmj4hMOZmO\nGwwGg+HU0ZCRxUxgQrW0h4FFSqkuwCLrdxVEJBh4AhgMDAKeqEmonEmYQIIGg6ElUG9hoZRaBqRV\nS74E+MTa/gS41MGu44GFSqk0pVQ6sJDjhc4ZgzLuUAaDoQXhLJtFK6XUUWs7EWjloExb4LDd73gr\n7ThE5FYRWSci65KTk53URYPBYDA0FKcbuJV+ZT6p12al1AylVKxSKjYsrPnMtm4UjBbKYDC0AJwl\nLJJEJALA+j7moEwCEGn3u52VdkZitFAGg6El4Sxh8SNQ7t00BfjBQZn5wDgRCbIM2+OsNIPBYDA0\ncxriOvslsBKIEZF4EbkZeB44T0T2AGOt34hIrIh8AKCUSgOeBtZan39ZaWc0RgtlMBhaAvUO96GU\nuraGrHMdlF0H3GL3+yPgo/q2aTAYDIamxczgNhgMBkOdGGHRxIiJJGgwGFoARlgYDAaDoU6MsGgi\njOuswWBoSRhh0cQYJXtjE2EAACAASURBVJTBYGgJGGFhMBgMhjoxwqKJUGZFC4PB0IIwwqKJMc5Q\nBoOhJWCEhcFgMBjqxAiLJsJ4QxkMhpaEERZNjFFDGQyGloARFgaDwWCoEyMsmgijhTIYDC0JIyya\nGDHT8gwGQwvACAuDwWAw1IkRFk2EMu5QBoOhBeE0YSEiMSKyye6TJSL3ViszSkQy7cr801ntt1SM\nN5TBYGgJ1HulvJpQSu0C+gGIiAuQAMx2UPR3pdSFzmrXYDAYDI1PY6mhzgX2KaUONlL9LR6jhDIY\nDC2JxhIW1wBf1pA3REQ2i8hcEenZSO0bDAaDwYk4XViIiDtwMfCtg+wNQJRSqi/wb+D7Guq4VUTW\nici65ORkZ3fRYDAYDPWkMUYW5wMblFJJ1TOUUllKqRxr+xfATURCHZSboZSKVUrFhoWFNUIXmx7j\nDGUwGFoSjSEsrqUGFZSItBbR/j8iMshqP7UR+tBiEOMOZTAYWgBO84YCEBEf4DzgNru0/wNQSr0L\nXAH8TURKgHzgGmUmHBgMBkOzx6nCQimVC4RUS3vXbvst4C1nttlyMTLSYDC0HMwM7ibGKKEMBkNL\nwAgLg8FgMNSJERZNhLHUGAyGloQRFk2McYYyGAwtASMsDAaDwVAnRlg0EUYLZTAYWhJGWBgMBoOh\nToywaGLMsqoGg6ElYIRFE2G8oQwGQ0vCCAuDwWAw1IkRFk2McZ01GAwtASMsmghl/KEMBkMLwggL\ng8FgMNSJERZNjNFCGQyGloARFk2E8YYyGAwtCSMsDAaDwVAnThUWIhInIltFZJOIrHOQLyLypojs\nFZEtIjLAme23RIw3lMFgaAk4daU8i9FKqZQa8s4HulifwcA71vcZh1FDGQyGlsSpVkNdAnyqNKuA\nQBGJOMV9MBgMBkM9cbawUMACEVkvIrc6yG8LHLb7HW+lncEYPZTBYGj+OFsNNUwplSAi4cBCEdmp\nlFpW30osQXMrQPv27Z3cxeaBmZRnMBhaEk4dWSilEqzvY8BsYFC1IglApN3vdlZa9XpmKKVilVKx\nYWFhzuyiwWAwGBqA04SFiPiIiF/5NjAO2Fat2I/AjZZX1NlAplLqqLP60BIx3lAGg6El4Ew1VCtg\n9v+3d+bhVVVXH35XQiDMQ0RFQcCCyJQAASUyOKACDigq4oADoqgVKbaK+LV1oFVxFkRFLYhWKn6O\nOKCgolbLJCh+KoOIxYKoRRQERSWwvj/WvslJuCGY3HPuvWG/z3OenPHeX/a+Zw9rr722WOlXDfiH\nqr4iIpcAqOokYCZwHPAp8CMwNIHfn1Z4byiPx5NOJKyyUNXPgLw45ycF9hW4LFHf6fF4PJ5o8DO4\nk4y3Qnk8nnTAVxYej8fjKRdfWXg8Ho+nXHxlkWTEu0N5PJ40wFcWHo/H4ykXX1kkCe866/F40glf\nWSQZb4TyeDzpgK8sPB6Px1MuvrJIEj6QoMfjSSd8ZZFkvDOUx+NJB3xl4fF4PJ5y8ZVFkvDeUB6P\nJ53wlUWS8WYoj8eTDvjKwuPxeDzl4iuLJOGtUB6PJ53wlUWSET8tz+PxpAGJXFa1mYi8ISJLReRj\nEfldnHuOEJFNIrLEbdcm6vs9Ho/HEx6JXFa1EPiDqr7n1uJeLCKvqurSUve9raonJPB70xL17lAe\njyeNSOSyql8CX7r9zSKyDNgfKF1ZeIJ4K5QnRLZt28batWv56aefki3FExLZ2dk0bdqUrKysUL8n\nkT2LIkSkBdAZWBDncoGIfACsA65U1Y/D0ODxeGDt2rXUrVuXFi1a+LVTqiCqyoYNG1i7di0tW7YM\n9bsSPsAtInWAp4FRqvp9qcvvAc1VNQ+4B3iujM8YLiKLRGTR+vXrEy0xJfBGKE8U/PTTT+Tk5PiK\noooiIuTk5ETSc0xoZSEiWVhFMU1Vnyl9XVW/V9Utbn8mkCUie8W570FV7aqqXRs3bpxIiR7PHoev\nKKo2UeVvIr2hBJgMLFPVO8u4Z193HyJyiPv+DYnSkI7419hT1cnMzKRTp0506NCBQYMG8eOPP1b4\ns958801OOMH8Y55//nnGjRtX5r0bN27kvvvu+9Xfcf3113P77bfv9Fk5OTlFjinz5s1DRFi7di0A\nmzZtolGjRuzYsaPMz500aRKPPvroLr976tSpjBgxIu61m2666df8GwknkT2LHsA5wFEB19jjROQS\nEbnE3XMa8JEbs5gAnKF7qFvQnvlfe/ZEatasyZIlS/joo4+oXr06kyZNKnFdVXdZyJbFgAEDGDNm\nTJnXK1pZxKNBgwY0adKEZcuWATB37lw6d+7M3LlzAZg/fz6HHHIIGRllF6mXXHIJ5557boU1VJnK\nQlXfUVVR1VxV7eS2mao6SVUnuXsmqmp7Vc1T1e6qOjdR3+/xeFKfXr168emnn7J69WratGnDueee\nS4cOHVizZg2zZ8+moKCALl26MGjQILZs2QLAK6+8wsEHH0yXLl145pli63awFf71118zcOBA8vLy\nyMvLY+7cuYwZM4ZVq1bRqVMnrrrqKgBuu+02unXrRm5uLtddd13RZ914440cdNBB9OzZkxUrVsTV\nfthhhxVVDnPnzuWKK64ocdyjRw8AVq1aRb9+/cjPz6dXr14sX74cKNljeffdd8nNzS3S1qFDh6Lv\nWbduHf369aN169aMHj0agDFjxrB161Y6derE2WefXclcqBiheEN5dh9vT/ZExQ0vfMzSdaV9TipH\nu/3qcd2J7Xfr3sLCQl5++WX69esHwMqVK3nkkUfo3r0733zzDX/961957bXXqF27Nrfccgt33nkn\no0eP5qKLLmLOnDm0atWKwYMHx/3skSNHcvjhh/Pss8+yfft2tmzZwrhx4/joo49YsmQJALNnz2bl\nypUsXLgQVWXAgAH885//pHbt2kyfPp0lS5ZQWFhIly5dyM/P3+k7evTowVtvvcWFF17IZ599xqBB\ng3jggQcAiiongOHDhzNp0iRat27NggUL+O1vf8ucOXNKfNbQoUN56KGHKCgo2Kl3tGTJEt5//31q\n1KhBmzZtuPzyyxk3bhwTJ04s+l+Sga8skoa3Q3n2DGItYrCexbBhw1i3bh3Nmzene/fugJlxli5d\nWtQ6/+WXXygoKGD58uW0bNmS1q1bAzBkyBAefPDBnb5jzpw5ReMBmZmZ1K9fn++++67EPbNnz2b2\n7Nl07twZgC1btrBy5Uo2b97MwIEDqVWrFmDmrXgcdthh3Hzzzfz73/+mRYsWZGdno6ps2bKFxYsX\nc+ihh7Jlyxbmzp3LoEGDip77+eefS3zOxo0b2bx5MwUFBQCcddZZvPjii0XX+/TpQ/369QFo164d\nn3/+Oc2aNSs3ncPGVxYezx7C7vYAEk1szKI0tWvXLtpXVY455hgef/zxEvcksiWtqlxzzTVcfPHF\nJc7ffffdu/V869at2bhxIy+88EJRQZ+fn8/DDz9MixYtqFOnDt9//z0NGjSolO4aNWoU7WdmZlJY\nWFjhz0okPpBgkvFGKI8Hunfvzr/+9S8+/fRTAH744Qc++eQTDj74YFavXs2qVasAdqpMYvTp04f7\n778fgO3bt7Np0ybq1q3L5s2bi+7p27cvU6ZMKRoL+eKLL/jvf/9L7969ee6559i6dSubN2/mhRde\n2KXO8ePHF1UWBQUF3H333UU9onr16tGyZUuefPJJwCqoDz74oMRnNGjQgLp167Jggc1Znj59+m6l\nUVZWFtu2bdute8PAVxZJwntDeTzFNG7cmKlTp3LmmWeSm5tbZILKzs7mwQcf5Pjjj6dLly7svffe\ncZ8fP348b7zxBh07diQ/P5+lS5eSk5NDjx496NChA1dddRXHHnssZ511FgUFBXTs2JHTTjuNzZs3\n06VLFwYPHkxeXh79+/enW7duZers0aMHa9asoWvXroBVFp999hmHHXZY0T3Tpk1j8uTJ5OXl0b59\ne2bMmLHT50yePJmLLrqITp068cMPPxSZnXbF8OHDyc3NTdoAt6S652rXrl110aJFyZaRcBat/pbT\nJs3j0QsOofdBfuKhJxyWLVtG27Ztky3DU4otW7ZQp04dAMaNG8eXX37J+PHjK/x58fJZRBaratdK\nCQ3gxyySjHeG8nj2PF566SVuvvlmCgsLad68OVOnTk22pHLxlUWSSO3+nMfjCZPBgweX6Qacqvgx\nC4/H4/GUi68skoxfVtXj8aQDvrJIEinuV+DxeDwl8JWFx+PxeMrFVxZJxntDeao6wRDlJ554Ihs3\nbqzwZ7Vo0YJvvvlmt8/vLosWLWLkyJEVfj7I1KlTWbduXUI+K5XwlUWSSPX5LR5PogiGKG/UqBH3\n3ntvsiXtRNeuXZkwYUJCPqsilUWqhPTYFb6y8Hg8kVFQUMAXX3xRdFxWyPCTTz6Z/Px82rdvHzdw\nYHns2LGD1q1bE1uWeceOHbRq1Yr169fz5JNP0qFDB/Ly8ujduzdQclGl66+/nvPOO49evXrRvHlz\nnnnmGUaPHk3Hjh3p169fUciNxYsXc/jhh5Ofn0/fvn358ssveeqpp1i0aBFnn302nTp1YuvWrXHv\nAzjiiCMYNWoUXbt2rdSEvKjw8yySjLdCeSLj5THw1YeJ/cx9O0L/slerC7J9+3Zef/11hg0bBpQd\nMrx3795MmTKFRo0asXXrVrp168app55KTk7ObsvKyMhgyJAhTJs2jVGjRvHaa6+Rl5dH48aNGTt2\nLLNmzWL//fcv0yS2atUq3njjDZYuXUpBQQFPP/00t956KwMHDuSll17i+OOP5/LLL2fGjBk0btyY\nJ554gj/+8Y9MmTKFiRMncvvtt9O1a1e2bdtW5n1g0XXTJUKFryyShDdCefYUYiHKv/jiC9q2bcsx\nxxwDlB0yvHfv3kyYMIFnn30WgDVr1rBy5cpfVVkAXHDBBZx00kmMGjWKKVOmMHToUMDiO51//vmc\nfvrpnHLKKXGf7d+/P1lZWXTs2JHt27cXrcHRsWNHVq9ezYoVK/joo4+K/pft27fTpEmTnT6nvPvS\naWJeQisLEekHjAcygb+p6rhS12sAjwL52Nrbg1V1dSI1eDyeMtjNHkCiiY1Z/Pjjj/Tt25d7772X\nkSNHlhky/M033+S1115j3rx51KpViyOOOIKffvrpV39vs2bN2GeffZgzZw4LFy5k2rRpgK2FvWDB\nAl566SXy8/NZvHjxTs/GwoRnZGSQlZVVtEhZRkYGhYWFqCrt27dn3rx5u9RQ3n3BMO2pTsLGLEQk\nE7gX6A+0A84UkXalbhsGfKeqrYC7gFsS9f1pi7dDefYQatWqxYQJE7jjjjsoLCwsM2T4pk2baNiw\nIbVq1WL58uXMnz+/wt954YUXMmTIEAYNGkRmZiZgJqZDDz2UsWPH0rhxY9asWfOrP7dNmzasX7++\nqBLYtm0bH3/8MUCJ0Oi7ui/dSGTP4hDgU1X9DEBEpgMnAUsD95wEXO/2nwImiohoCK5B3/+0jc0/\npa6HwTdbfi7/Jo+nitG5c2dyc3N5/PHHOeecc1i2bFnR2hB16tThscceo1+/fkyaNIm2bdvSpk2b\notX0yiM3N5eMDGv/nn766dx5550MGDCAoUOHFpmgAK666ipWrlyJqtKnTx/y8vJ46623ftX/Ub16\ndZ566ilGjhzJpk2bKCwsZNSoUbRv357zzz+fSy65hJo1azJv3rwy70s3EhaiXEROA/qp6oXu+Bzg\nUFUdEbjnI3fPWne8yt1TpoN0RUOU3/vGp9w2K/7C66nE05cWkN+8UbJleKooe3qI8kWLFnHFFVfw\n9ttvJ1tKqOyxIcpFZDgwHOCAAw6o0Gcc2WZvGtepUf6NSaR2jWp0atYw2TI8nirJuHHjuP/++4vG\nKjyVI5GVxRdAcFXxpu5cvHvWikg1oD420F0CVX0QeBCsZ1ERMe32q0e7/epV5FGPx1MFGDNmDGPG\njEm2jCpDIiflvQu0FpGWIlIdOAN4vtQ9zwPnuf3TgDlhjFd4PB6PJ7EkrGehqoUiMgKYhbnOTlHV\nj0VkLLBIVZ8HJgN/F5FPgW+xCsXj8YSIqha5fnqqHlG1txM6ZqGqM4GZpc5dG9j/CRiUyO/0eDxl\nk52dzYYNG8jJyfEVRhVEVdmwYQPZ2dmhf1dKDnB7PJ7E0LRpU9auXVsUI8lT9cjOzqZp06ahf4+v\nLDyeKkxWVhYtW7ZMtgxPFcBHnfV4PB5PufjKwuPxeDzl4isLj8fj8ZRLwsJ9hIWIrAc+r+DjewEV\nX2sxGrzGypPq+iD1Naa6PvAafy3NVbVxoj4s5SuLyiAiixIZGyUMvMbKk+r6IPU1pro+8BqTjTdD\neTwej6dcfGXh8Xg8nnKp6pXFr1/pPXq8xsqT6vog9TWmuj7wGpNKlR6z8Hg8Hk9iqOo9C4/H4/Ek\nAF9ZJBERaS0iHZOtY1eIyN7J1lAeInKAiNRJto6ycGH7ww/eUwlEZD9J4UiDaZKG6aCxwmWOryyS\ngIhkisiDWITee0TkShGp2JKAISEidURkMvCqiNwgIj3c+ZT5zYhIDRGZArwOPC4ipydbUxARyXJp\nOBt4VEQuFJGaydYVRERqBtLwIRE5LtmagqRJGqaDxkqXOSnz4u9hHAA0UNXW2PKxewG/FZFayZVV\nguFALeBI4CvgERHJVNUdyZVVgiOB+i4d7wOGicgxIpKZZF0xcinO5/8BegHnikgqrfd7GlBHVdsC\nrwE3iUgqRR5MhzRMB42VLnN8ZRERInJgIGNqAN1EJFtVPwFmADWBpLaMS5lyFJinqt+q6v3Ah8Bf\n3H1JM1eIyD6Bwx1AbQBVfRl4FTgWaJMEaQCISNNA+mQArVwlOx94yWnrnSx9ACISXPhdgfUAqjod\n+CdwsYjUT4Y2SJs0TAeNCS1zfGURMiKyr4i8BUwDZohIJ2Al9oM6x932AfA+0KHUixyVxrYi8gww\nWUT6u/XRM4FgqIArgbNEZH9V1agrDPfDnwVMF5HrRGRf4EtgmYh0drf9HWsxtY1Sm9PXTEReBx4H\npopIK2A18CbQz902G9gEtBeR8Fer2VnjQSLyAjBNRIa5CmELsMWlJ8BtQAHQ2j0TWT6nSRqmg8ZQ\nyhxfWYTPIOA9VS3AWr5/wF7GfwFdRaSZqv4IrAGaAlujFCciWcDdwHzgCWAg1pV+GBgoIgcBqOoq\nbMnca9xx1D7XY4CFwKlAI8yffRXWOsoTkbqq+jXWAzoDIu8BXYwtH9wL+AK4FaiDVWhdRKSxqm4E\nPgV6ulUjo+YmYAHwJ6ALcBfwMtARK9iqq+oa7LcwCiLP53RIw3TQGEqZ4yuLkAgUVFlAdQBVvRXr\n8h+C/bi+xDISVX0d2B+oF7HU/YH1qnqrqj4D3AicDOyNtdSvkWKPqFeAtVGKE6Ma8D0w15nFfgc0\nBw7HWkv5wDHukSeALBGpGUVBFxjwL8TyE1X9H+zd6gW8B9QFznb3PQc0itLM49KwIRbgbpqqvgeM\nwEx2XYDHgMGY7R1gOvB9VGM/aZKG6aAx1DLHVxYJRnb2Fvoa+FpEWrjj6dhL+QswGThaRO4WkY+A\n/8MKxSh0CoCqrgYKRORwd/w58BAwDms1AdwgIhdiYxaRrM/pCjhRoxAzLwW7y2OBv6rqC1iL6UoR\nuRbr/SxS1VB7aIH0iw34bwcKA4XDROAsLE+fxQbfx2Et+4WY+Sd0Amn4HdAON57jKtIxwP2q+g/g\nP8CfReQKrJHwiapuD1ub05KyaZgmGqMpc1TVb5XcgGZYi6JWnGsHuww6keIZ81OA691+C+AE4LSQ\nNe6NeQ7Fu3YZMCdwvBfwNGb73wszTU0HTg9Z435AlzKunQS8A9QOnJsPDHH73TAT2eAQ9TUF+gIZ\nca71wFqTHQL5PAu4wu23BYZGkIb7Ai3KuDYU+LjUudeBo93+UcAEn4ZpoTHyMie0f2ZP2bDu/L+x\nVsUk4PzAjyqWOVdi5p0j3fHJ7qWUiDT+FVgHPAVcHTg/yhUu1VxBfLE7Xw0zTRwUYTr+GbMBzwLu\niH035q1xgtt/AbgKaOiOrw6zYCulbzTW+p6JtSb7uPP9geFuf6L7P9q646HA6AjT8AaXzzOxXmBd\nd34YrhLGBjVHBp65E+jl0zCtNCalzInkn6vKG3ALcITb7wvMw1oXdYAcd35f4FJgMdb1XwOcEpG+\nztggpmAmiDeBQe7aubjeBmZ3XYW1OIYCi4BWEWlshPVc6mJzO27CBl8bYD2GWDp2AP7hrl0GfAb0\niEBfdeABoKU7Hg48ibXuWgT0HYiZ72YAV2CLdh0bURq2cN+b6X5vjwG/d8f9AxoPAd4GLnf/x1Ig\nz6dhemh035+UMieSf64qbVgXr73br+EK316B69cAz5fx7HHAtUDvkDXuE9hv435MsUrhPKw1kh/n\nuVOw1sibQPeQNTbHJoOBVRCf4yonzL56C/D7OM8diHmkTCPEigL4DbCf288GlscKVcykdwMwIc5z\ntTFvrHsIucWODU7GzAyNgU+AJu74WGB8vAIC84wZDbwIFOzhaZgOGlOizAntH6xqG9bqmIa1xN4G\nRrnzo4DXAvc1xNzVjnLH9YCTItLY0GlcDFyP9Spy3A+6t7snC5vtfDHOJosz60SksTbWi1iKeTKd\n5M6PBf7s9gWruCZQ3MqrD7SJQF825kO/FHgLONedvwaYErivs7uvS0Bf6L2cwG/qcWxwcnLgt3Yb\ncI7bz8RMEX+m2GzXAGjk0zBtNKZUmeO9oXaflkCmqrbDbIb7icgNwFSghoic7O77BXgX6waCuSZm\nQiR+/yOAn4E+wGZsrsT37lwXEdlHVbdhg5pDtNjD4yGJLqDhsZgzTjss7S4UkT6Y2aupiHRV+8Wv\noqQP+CW4NA05HfOx1no7rAI7UkSGYTbs+iJylLvvG8zTJRbS4UScC2IE+XwmUKiquViv8UaxEB3/\nAQ4WkdZqnkyLsUbCd+65G4BWEWhMhzRMB40pVeb4ymL3qYVlAqr6AdaFbwwchtnY7xSR2qr6A5bJ\nsRf0n2rzF3CFYMIJ/CC2YXMRNqrqHdgP/ULM7nowbi6Cqj4NbBWRJu65c1X1wzC0xdGo2EQ6VPVJ\nzL2wJ1a5LcNeilga5wCx8B53qepb7loo6eiohpkmUPNDn4OZ8vbBBhTHumtrcGYg99x0tZAjUeTz\nDsw9ElX9G9byPBUbvAY3KVFV38AKld+481er6sIwNTpSNg3TTGNKlTm+siiD2IsZ8GFeCbwjIme5\n4yVuO9L9eGYBd4vIQqAJZj9GQwy8F/ABj/0gGmKDxTGuwibgfIy5+50jIreJyD+xVuh/3fM/hq0x\nwI/AChHp4I4fxcYhamKDsgeIyBQReQf78a9xGn8JU18gn78G5rveDli+/gy0VtXHgG9EZLKIzMPe\nn9VOX2FI+uK9oxnAZhGJhWO5DXNM+AZzADhKRO53+byW4klkocwmjmlM1TR02lI9n4t6Kylb5kRh\ne0uXDeteXoR5PtQMnM9yfy/EBof3csfHYy0NsMLuAGBgyBrrOI0141zLxWK+NA2cewK4we23wiqP\n4SFrrIuZwuL5gDfGQnUU+Yhj4yuPuP1G7tnzQtRXHbifON5emC37Osx2HXMKGA48Hvjf8oCzQk7D\n+tgAdR9K+ftjletMzFWymjv3AHCf22+CTRQbFqK+ephbcyPMVJKKaZgu+TzBbXUD51OmzCnSFMWX\npMOGmT8+xuYiPEqxv3Jd4Hmse9oWa8WNc9dqY54JUQ4Q346NQ1wWOHc0cLbbn+QKmcbueAjwuwj1\njQJWYF3mJygeWG8L3IzZUs/H5lIMcNcOBv4XqBGRxu6YKWdC4Nz+wN9cfh/t0vkyd21frBVXOyJ9\nh2MmpUnYpMga7vwhFE/++hPmQhwbeO3tjjMj0Pc7zGQ4A+vJnJ9qaZgm+bwvFnTw7tj76s6nVJlT\npCvqL0zFDWuRP0ax500fbHC4mTuO+S4LZudc7n5ky11GVo9AY6wFOQIbqJwBHOzO9Qb2d/uN3P8y\nEWuVLAfOiCgd+2NrIjR1x+Nw7q/uJd3H7dfCXHjnY0ELV8QKwYh0/gab0foJ0Nedq0NxBVvdFdjL\nsAmNKzD3w51m9CZYV8wN9lwCFTzFXmttAvlcD7OrP4cV3iuAiyJIu55Yryb2blzk8rmm25KahumQ\nzwF9+cCLgeN6gf3Yu5K0Mqf0Fvtx7nGISCNV/TZw3ElVl7j9zlgr+ASNY6MUC0vcHhsueD5EjU2A\nH1T1+8C5CdiAZn3sB/X7wDVRVRVb2rEHFqbjcVWdEaLGfZzGLWIRbNuo6kfu2hnABap6bBnP9sBe\n1qWq+lxI+hqp6rextHHnhgIx+/1lqtpTbC2C7aWezcMmBa4POQ1L5LOI/B1rDMzETHafY4OWs0o9\nVxNLv+OB10NMw/0AVHWdO85X1cVu/xhgjKr2KePZqNIwHfK5JWYSe9UdF2BhbB7ErAFbnN4LYv9D\n4NlIypxdEnXtlOwNm2dwDza4G9df2mXKTKw7KG7LwOz9oYfocN91JzYI/SwwInAt5v7YDJun8DBw\nTOB/axdROtbAJs59hJnuRsS0B+4ZSnH3OdYwycRekFDTMV4+41pjwBEUj+O8i7ntjg7oG5qkfP6d\nO38G5iU2FZuFOxIz6Z0fSPueEeXxbVjL+2Xgj3HuOcbpzKK4B5QRYRqmfD6777sBC9HxMmZ26gIc\nhAXBHItFJKiNRXa+PfZ/RFXm7M62J3pDnYoNst6PTVgqIuCFcAiwRVU3q+VabDnRHzBXxLD9qw/B\nWugHYDOqTxGRAe5aHcyW2Rc4lOI49WAxgNqISEaYGp3nxkTMnl6AtYquF1tTYoeIVHe3tgW+hRIe\nWx0wE0q1kNNxp3zWYo+q5sC3ItIXsxu3wtyLodhXPSsJ+Xyyy+f5mLdOHbVVCmNrJ3d2mo7FfO4z\nw9IotiToTdhvrSM24/t0cZFMA3ncGdisqttc3mdgplAhmjRM+XwWWwCpGfa+DsDMYtdgsdAWYkvb\nvqHmAjscONu9vYQjJQAAERNJREFUS7/g5nhEkI7lk+zaKqqN4pZtNuaTXB3zrb7Anc8M3DsG69p3\nwswBJ0astRM2YzPbHQ/HCufuwB8xV8g3MDPTYzivFyKyY2K26SNKnXsKN2AdODcNW3Gtq9MfxQzs\nXeazu9YTG/h8y93zFHBPEn6TpfP5YopbnadghUnQYyw2/lMtAm2ZmE29RuDcE7hgk4Fzd7vfZWcs\ntPlhEaVdOuVzPcwNNjYmui/WY/sjNqv+HYojGfTGZuVHPiZR7v+RbAFJ/efNN31x4GXNdH9nYP7p\n84BTw/4hxTnXGTNPFLjj2ljrcjBmwukXuHcAEYUfKKWxpvsr7mWYT/Ggp2BxdeZjazq/G3Y6/sp8\nrkcgNhbmftg/CbrKyueh7ngC5rnzNNZ7jDSfKfbCynCVxywgN3AuG2u0fIit35C0PE6VfAb2LnUc\nM83dgfPKcu/HIVgvpzFmyhuLmaDeo1SjK1W2pAsIKcMEa7Vl7cZ904CbAscZrnD7QwQ6/+ResliQ\nsFhrqY4rKH5LsSfWUODl0voj0HgTLuZMGdczXCE3i5JzU/bF1iEOLR0rkM83u+NgL3KXzyZI4zWY\nqaG1OxfzbIuXz+dhg9WxtG2Fi/cUch6Xab8P6J2N88aKpR02EfCqCNLwWqwnHQs2GW+tiaTls/uO\na7CezDmlNWINgxeBbu74QGysp2PgntDHoSqzVbkxCxE5Eiuk7qF4mci4qOXQGKCviFyHuaZVwyI6\n3hGixiEi8jbmybIBm9WMqqrz5tiCvZjtKF4u9DF7VBqU0h8azgPjd1gY5riojeXkAt+o6lYROU9E\njlfVr7CCJZR0rGA+Hyu2mt6N4paKVYuVFQoichg2qJqHFRYPue8sFJGMMvL5H8A2EWmoqjtU9VNV\n/XuIGhtgA+r9scmoO+H0tsXG8b5wv99hLu0OUNXbQtS3H9bi7ui2Z0SkvsaZpZzEfB4oIu9hYyR3\nYPlJKY3LsZhsN7lrn2GLfRWVwar6TlgaE0GVqizcQFIOFm3zXaC72NrDu2JvrPV2EvCMqv6iIS6y\nLiL52KS0K1X1GCxEx2HuWkasAlDVFzETzoUiciNm11yBFZChUiokwmNAMxG52F2LN9DWBwu+9r+Y\n3/06AFcYhqGvMvl8MhbO+b9haCtFLhbB9AysB7FEite1joVqKSufN4YpLJDHmzHTRz1goHPHjUdP\noLGIPIONrSyBcEPFOGpjPYRBqjrWaf1TsNFUikjzWUT2x7wnL1PVS7DBa3XXghXBVlW9C9guIpNE\nZBHWSFwXpr6EkuyuTWU3isNDxOyrDdzfY4FHKDUQW+rZHGzQK9TJTE5jN+IMTGLxm+4qdU4C+we7\ne84PWWMOFvs+OKDZF/OC6Q4si/NMzB4bc/88cw/P5xJpCNyLzcLuhs3IfRebVNnIXc8KPBt6Prs0\nPKpUHudhKw52xQaImxAYXA3k8R8w99SwlwttQEnzTS4WyiQ2AbUp5hnWJ8n5PIg4yxS7d2Z1nPOx\ndKyHOTCEmo6h/N/JFlDJTLsaa4W9hLWAu5e6Pg6L/9LCHQdtmBL8G6LGS7EW+kxssLJdUAvmQx+b\nixDZ7NZSGodhnjcvYp4Yx7vzvwEecPtPY626iXGezyfEMBNpks/BNHwEc5PMwUx4yzFvsA5YKJnn\notC0izQs8lpyGme4/TuxAeLHCMQpctcODPv3iYWK2YFb18Sda+IqgGMpjpd0NfBEvPyNIJ9HY/NO\nnnfpdJY7H6sM6mBzZkJd4CwZW9qaoUTkVOBIzJPkeOArrNBCRKq52x7HJr60cMe13PWguSc0u7+I\n1MJa5QWqepzTOFxE2mrxLNL/ozikdGgRasuhAxaM7ATM6+YcEemCtfK+F5GuWFe7FVYYxqJjxkwp\ni7XUrNhEkQ757Aim4VtYS7ylmunhRVUdoTazfTjQXkSaR6AJiJuGX2NjKGAeQstFpDfWK2oKvKqq\nm92zsTz+LMzfp4i0xubtjAAGu1ntqOqXOK9Epw1sXk8HETmgdP6G/D4fjS0/3FNVBwBzgbYiUjOQ\nNnWxWdg/umeSPz8iQaRtZYHNhBylxSE7PsHMFKgNyIlaDPhXgUtEZCkWwiOyQlnNnluA2VHBWnQb\nMRfYGO8AH4jIEVFoKoPeWPgQMLfhdzG79BqsZ/QwFpDwHmzAG3VEoC3l89lROg3nY2kHcKKIdHP7\n3dy1ryLUFi8Nj3b7n2EF9ETME+t6YIC48OdRVWiquhKYrKr3YRPVxgYuT8TmUZwXC5mBjZl8HYW2\ngMbXsF7PBnfqK6Czqm4N3PMl1lg5Oc5HpDVpUVmIxRwqgar+qKrLA6dq4AbdXG0eq9EHYHba+1V1\nRNhaYwQGMh/GXP5Q1RXYi5AjxSvTNca6rqHF8t8NjY9glQPuRZhJ8cIrh6hqR1VdhBUkoXnmxCON\n8rl0Gr4M1BRbeOg+YLxzALgbeFNVf45KYxlp+L7reW3CzHq5qroA89h6WFXXR6UvwGr39ypsTY5D\nAVxa3YbNZp4CPAP8K8o0jKEufpxjB/CFuIgJgZ7uTMwZoFpUlW0UpHxlISKXAs9JqWU/Y927QNiB\ngzE31Fird4eI7IsVzi1V9Z4QNQ4RkcNFJCemLWCWWQA0cq6eYK26JthCK7GWyIPuvtAQkT4i0jxw\nLKq63aXj8+7cKe7yt5jX1Q5VXequVVcL6fCPqPSV+psK+XyaiOTGKohy0nAD1otsqarjMfPTi5hb\n9uSo9JX6WyINYz0vdaskikgNVS1U89AKBZdXO5lnXFqqiGS5yvZvwF8CtyxX1duxMb5c1wOJXKP7\nG2u8dgG+VXNxVqzyAJuoOEJDXMwpKezu4EbUGxZuYxZmpllKcWjmTOJPyHkCC4PdC3NT3GnBkxA0\n5mEDgrOwFs9NFAcxi01kqodNuppO8SDcK1ihEUU6dsTGRV7ABuTOpHj2ddDr5TRsTkAsvMT/4ga6\nk6hvp4lUScrnltjg/msuXcbiBoAp6VkULw1DDxVTjr6dwkaUSsPxwEERaOyOmW0+LHVe4r3P7to8\nzAT1MnBsqmnE4lF1wCI8P4r1wkPVmMwtJXsWbrDrWuBeVe2JxVUZBKCq29VakweKyB9EZF83GNYa\nm9B0G/CKqn4assYMrEKbpKp9MTt1hrogZmr29AMx88gr7rHpIjIbs7+Gqs9pFGyB+YmqeiLWWuuD\nzdZFVX9x6XglNjnsfeBBEXkDmzC0Isn6tiU7nx37Y2aPo7HfZSNs/QNU9edy0nBZkvX9Uk4azlLV\nT8IUJzYvpicWC+l7sdDhOH0aeJ/HicgB7pkaFIfCeEhVZ6eQxhZOXxfMLHs75p21MEyNSSfZtVWg\nls7CPFriLRc6EuuSxtxNT8eC6V3sjg/EIsJeFrLGakGNWEv4Wbc/BWvZHYkNaA/AQiHE4vzUwGZs\nh+0DXlpjUfgDd/y80/kboB/mO39JIA/aAeemmL6o87n0MqYjKF5us5rT8X9YqJGjgfURp2FF9CU7\nDVu4v/2xFSmDS4geh1Wql7vjTGz8Z3QKahzpjutRasXKqr4lXYBL+FNcofAc5s8fm7QU810ejQ1c\nxu5vQKllBYmz3nOIGp9zhUIDrDW8Auv+n4dNIBqPtYoiXfqwlMZn3Q+6J2ai6INVsg9jy29ejA1i\nNww8H7aPeqX0RZTPl2LrmF8cOFcXa5y0D5y7GjODVYs4DSulL1lpWOr6s5RsINSl1AS30gV5imrM\nDlNjqm1JN0OJzUUYgNl2T8YGBUeKSDstdn18EegvInXc8feq+p0E4vlriGEH4mjcgE0CywF+DyxU\n1dNV9RHMm6QJ1nL+LuAtEypxNH6HTQhbC9yKFdTnYwXIF9jg9Y9BjeregFTUF1E+dwYuwCqz/lLs\n678Z82j6q7svExtQz8Ran1GlYaX0JTMNncdQ7F24Gjgjdg2zGGwSkeoBjWHO6UiUxtDCAqUiSa8s\n3A+3DTYhBywQV03g6EDGfYV5GOS7Z2JeHNvDfDnL0ZiFdVd/AhqKSGxZyb2An1X1PzGNYesrQ+Pt\nWFydE7ABzRGqepyqvo+NmdQKPBu6xsrqiyif3wfOxiqsz4DLA5dvxSZgne/SqxbWsvwupjHV9SUp\nDUe48zvUPMeqqY2R/A14WEQexQWqVIvL5jWmKEmtLMTIwPymOzj3uaWYvbUZZtsGc0nrAoQWObKC\nGptjq8HNBu4XkVuxl3Ze7Nkka/zAaWyjqioie4nIWKwF/3YU2tJBXxBV/UTNdfNpoKPY7HXUfPov\nB04SkSexgmYBRDtLN9X1xdGYG9MoNq8j5k7aEDM9rlXV66LUly4aU43IKgsRKRDzcipCjR3Y2rT7\nYAPAYOESuuAmqqnqRqw1H6pnSQU1/qiqE7AIqF8Dx6nzAQ+jBVJBjbFW71nu+lGq+l6itaWDvrI0\nxuFDLPTJb2MnVPVV4FzMA6a3qj7ozic0n1NdX0U1xiwCYqHbweag/E+itaWTxnRCQvgdlfwCC3Nw\nA9Yt3ob5TT/vWpJZau6RDbABp4bALaq6QUSewqb/vxyqwMppfBoLQf1SCmt8Cpiqqi+67nUoE4VS\nXd9uaMwMmpJca7w5Njb1uXvmXlX9fE/VlyCNdwFfhWnKSQeN6UioPQuxAelbsEBqR2CTawbGMsEV\nIHthETrfxGzV/xCRRzAXvw/D1JcAjS0xU0oqazyQ4rUHwqooUlrfbmrcLiI5InKyiOS489uwiZeX\nAP8JuaJIaX0J1PhlyBVFymtMWzQct7RgiOjswP5dWIz/37jjPpgr5e8D95yMhSoOdcFyr7Hq66uA\nxq+waLGxHvc0LHhiaEtypro+r9FvsS2hZigROR0L1/CAqr5S6tqNLqNmYJOFZmKhEb5X1TUJE+E1\n7vH6EqVRRLI1JPfIVNfnNXp2IgE1eqzC6Y6ZZF4E/gTs587HYiTVCjxzKVaTx2LoZMQ+J4zNa6z6\n+tJBY6rr8xr9tqutUmMWYpFIY12TZZjP/Fhs9vKRUMIOvTXw6KdAPXWTg7Q4amPC8Rqrvr500Jjq\n+rxGT3lUuLIQkcuBhSLyFxE5QVU3qeoatWBan2G+y+1KPiLVROQybPnGt2InK/MPeI3hakx1femg\nMdX1eY2e3aIi3RHMT34B5iN/BrayWo/A9TZY5lweOFcPuBGLwNoh7C6T11j19aWDxlTX5zX6bXe3\n3R7gloB/soichi1Acq07vhS4VFVzA/efjkXfXIVNbBkrIg3VhR8IA6+x6utLB42prs9r9FSEcs1Q\nYgHIbgJuEpG+7nQhtuYwAKp6P7BDRIYHHn0HiyJ6Jy7OT5gvp9dYtfWlg8ZU1+c1eirFrrodWNdv\nCbYi1DCs69fTXVsBnBO493jgZbcvWMju54CcMLtGXmPV15cOGlNdn9fot0rnTTkZ16tU5owHbnP7\nJ2LT47PdcResRo8tK1o/0WK9xj1TXzpoTHV9XqPfKrvtcsxCbA2C7UCh2jT5M4HOwBi1ZQYfBn7B\nVjYbBGxS1YvK/MAQ8Bqrvr500Jjq+rxGT2XZ5ZiF2uIzP2tx4K2+wBotXphkFLYM5mBgRTIyzWus\n+vrSQWOq6/MaPZVmd7of2IpbGVhQrliMlQ5AHbcfanwfr9HrSxeNqa7Pa/RbRbfdnZS3A1sZ7hsg\nT0RewAJxVXMVzi+7+Tlh4jVWnlTXB6mvMdX1gdfoqQi/oqbvjmXgO8CwZNdyXuOeqS8dNKa6Pq/R\nbxXZfs2kvKbAOcCdaks4phxeY+VJdX2Q+hpTXR94jZ5fT+gr5Xk8Ho8n/YlsDW6Px+PxpC++svB4\nPB5PufjKwuPxeDzl4isLj8fj8ZSLryw8Ho/HUy6+svB4PB5PufjKwuPxeDzl4isLj8fj8ZTL/wMF\nOMs9pdsC+gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f68d6b0e630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result[['Predicted Weight','Real Lysimeter']].plot()\n",
    "#ax.show()\n",
    "#print(\"yeet\")\n",
    "plt.title(\"Halifax 2013 Real Lysimeter Data and Predicted Data\")\n",
    "plt.xticks(rotation=30) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1499\n"
     ]
    }
   ],
   "source": [
    "print(pred_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
